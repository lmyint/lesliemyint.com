{"/":{"title":"Leslie Myint","content":"\n\u003cimg src=\"/portrait.png\" style=\"width: 200px; float: right; padding: 0px 0px 20px 40px\"\u003e\n👋 Hi, I'm Leslie.\n\nI teach statistics at Macalester College with [awesome mathematicians, computer scientists, statisticians, and data scientists](https://www.macalester.edu/mscs/) as colleagues.\n\nI have a secret subversive plan to make academia as joyful, meaningful, and giving as a campaign of Dungeons and Dragons. To do that, I [[garden|write]].\n\nWelcome to my digital garden, coconspirator.\n\n\u003cstyle\u003e\n#footer {display: none;}\n\u003c/style\u003e\n","lastmodified":"2022-12-08T21:09:07.526176752Z","tags":null},"/12-Favorite-Problems":{"title":"12 Favorite Problems","content":"\n1. How can I truly reach every student without burning out?\n2. How can we make inspiring and successful education available to everyone?\n3. How can I be the best mother I can be while maintaining my own well-being?\n4. How do I contribute to a fulfilling marriage for me and my husband?\n5. What do I owe the world?\n6. What can I do to help safeguard human knowledge?\n7. How can I convince others to take meaningful action without forcing them or being preachy?\n8. How can I maintain a clear vision of what truly matters and let go of what doesn’t?\n9. How can I find the strength to change myself when it matters most?\n10. How can we fix the way science is conducted and funded?\n11. How can we create a more data-minded society?\n12. How can I infuse the best parts of games into all that I do?\n","lastmodified":"2022-12-08T21:09:07.526176752Z","tags":null},"/12-Favorite-Problems-The-key-to-classroom-community":{"title":"12 Favorite Problems: The key to classroom community","content":"\nWhat are you obsessed with?\n\nThis question has the power to completely change the game in classroom community-building.\n\n## Building community: why and first attempts\n\nCommunity is more than just hot chocolate for a teacher's heart—it has immense benefits for students:\n\n\u003e Community building is vital to active student engagement in a course across all modalities. Research shows that when students feel that they belong to their academic community, that they matter to one another, and that they can find emotional, social, and cognitive support for one another, they are able to engage in dialogue and reflection more actively and take ownership and responsibility of their own learning.    \n\u003e Source: [Columbia University, Center for Teaching and Learning](https://ctl.columbia.edu/resources-and-technology/teaching-with-technology/teaching-online/community-building)\n\nBuilding community has never been easy. I teach at a small college where small group activities are the primary venues for peer connection, and every semester students point out that group work is a space for improvement: some of their groups just didn't mesh.\n\nI get it. The mix of different personalities, identities, experiences, and motivations in a classroom lead to substantial variability in the success of group activities. The remedies that I've tried have been transformative for a handful of students but have had close to no effect on my courses as a whole: setting community guidelines on the first day of class (and reminding students of key guidelines throughout the semester), including emotional check-in prompts at the start of each class, using [collaborative group roles](https://uwaterloo.ca/centre-for-teaching-excellence/teaching-resources/teaching-tips/developing-assignments/group-work/group-roles-maximizing-group-performance), and requiring weekly reflections on group work.\n\nI want to try something radically different.\n\n## What are you obsessed with?\n\nImagine being asked this right off the bat in any potentially awkward social situation (e.g., meeting new people, the first day of class). Imagine someone saying those magical two words: \"Me too.\"\n\n\"What are you obsessed with?\" is a [lightning lure](https://lmyint.github.io/writing/lightning-lure/) of a question. The sparks that fly when a connection crackles into existence could set the world ablaze.\n\nA framework called the \"12 favorite problems\" (12FP) is a series of lightning rods for channeling that electrifying question.\n\n## The 12 favorite problems framework\n\nNobel prize-winning physicist Richard Feynman once said:\n\n\u003e You have to keep a dozen of your favorite problems constantly present in your mind, although by and large they will lay in a dormant state. Every time you hear or read a new trick or a new result, test it against each of your twelve problems to see whether it helps. Every once in a while there will be a hit, and people will say, \"How did [they] do it? [They] must be a genius!\"\nSource: [Forte Labs](https://fortelabs.com/blog/12-favorite-problems-how-to-spark-genius-with-the-power-of-open-questions/) (pronoun changes are mine)\n\nEssentially, Feynman kept a dozen profound, open-ended questions in the back of his mind all the time. Every learning experience was a chance to explore: could this help solve one of my favorite problems?\n\nGenerally, the answer was no. But the occasional yes's resulted in [monumental breakthroughs](https://fortelabs.com/blog/12-favorite-problems-how-to-spark-genius-with-the-power-of-open-questions/) in physics, computing, and other problems he found beautiful.\n\n## 12 favorite problems: classroom edition\n\nIn the classroom, the 12 favorite problems framework has the power to build community through genuine *****thought partnership*****. Here's how:\n\n- **Brainstorm:** Have students brainstorm their favorite problems as early as possible in the semester. This [guide](https://fortelabs.com/blog/how-to-generate-your-own-favorite-problems-a-4-step-guide/) by Tiago Forte contains excellent prompts (Steps 1 and 2).\n- **Share:** Have students post their (draft) favorite problems on a course discussion board and enthusiastically comment on their peers' posts. (I like Slack for the absolute [bonanza of emojis](https://slackmojis.com/) available to accompany this process.)\n- **Connect \"thought partners\":** First, group students who have connected via the discussion board to identify *thought partners*. Dedicate time in class shortly afterward for thought partners to give feedback on each other's favorite problems. Tiago Forte's [guide](https://fortelabs.com/blog/how-to-generate-your-own-favorite-problems-a-4-step-guide/) (Step 3) provides guidance on making the favorite questions specific, counterintuitive, or cross-disciplinary.\n- **Anchor:** Use the favorite problems framework to anchor assignments and reflections throughout the remainder of the semester.\n    - **Projects:** In my statistics courses, one or more of a student's favorite problems can directly lead to the topic for a long-term course project. In my statistics courses, it's completely ok if a student wants to pursue a project that doesn't have data. For one, it opens an opportunity to connect students with our campus librarians to attempt to find data. Secondly, if that search doesn't pan out, the student can still plan a study and advocate for future data collection. Mimi Onouha's [Library of Missing Datasets](https://materialising-data.org/2020/06/19/mimi-onuoha-the-library-of-missing-datasets/) is a powerful example in this regard.\n    - **Open-ended questions on regular homework assignments:** These are questions pertaining to current course concepts that can be investigated in the context of students' favorite problems. (e.g., Discuss the ethics of data collection in the context of one of your 12FP. How might confounding play a role in an analysis related to one of your 12FPs?)\n- **Regular feedback with thought partners:** Most importantly, whatever 12FP-anchoring strategies you choose, build in regular opportunities for thought partners to provide feedback. For individual students, this feedback sustains the energy of working on something meaningful, but because the dialogue is part of a *thought partnership*, that energy is automatically shared. Every student will have a peer invested in their success and be that peer to others.\n\nI am beyond pumped to use the 12 favorite problems framework to foster community in my courses next semester. It's the perfect supplement to my thoughts on [passion as an explicit course objective](https://lmyint.github.io/writing/different-kind-of-learning-objective/)—it's the recharge station that sustains passion's [wonder sprints](https://twitter.com/lesliemyint/status/1594764850596835328).\n\nLFG\n","lastmodified":"2022-12-08T21:09:07.526176752Z","tags":null},"/A-beautiful-life":{"title":"A beautiful life","content":"\n- [[Lightning Lure]]\n- [[The twin brushstrokes of my marriage and career]]\n","lastmodified":"2022-12-08T21:09:07.526176752Z","tags":null},"/A-different-kind-of-learning-objective":{"title":"A different kind of learning objective","content":"\n\u003e **Course learning objectives**    \n\u003e By the end of the course, students will be habitually inspired to pursue their passions and uplift others in pursuing theirs.\n\nI vow: this learning objective is going in my syllabi for the spring.\n\nI need my students to feel joy in learning like I need to see my daughter's 6-toothed smile. I've been told that feeling responsible for my students' intrinsic motivation is a high bar.\n\nBut I *need* to reach.\n\nWhy?\n\n*Memento mori.*\n\nThrough the Olympian highs and abyssal lows of my year and a half away from the classroom, this phrase has centered me and suffused me with purpose. In moments where I need it most, it squeezes my finger and arrests me with its frankness and beauty. Like looking up to see my daughter gazing out the window, transfixed by the snowy expanse outside, drinking in the *everythingness* of the world.\n\nStudents deserve to experience this kind of beauty. Until now, I had never thought to make this goal explicit. If [feedback loops](https://gradingforgrowth.com/p/the-heart-of-the-loop-reattempts) fuel lasting and meaningful learning, beauty is the ultimate accelerant.\n\nWhat exactly do I want to cultivate?\n\n- **Inspiration and wonder:** Everyone is naturally curious and observant about issues that, if addressed, could make the world a better place. However, these moments of notice are fleeting, and a path of passion dissipates before even being recognized as such. I want to help students cultivate a habit of *noticing* and *running with those observations* using a data-oriented mindset. \"Geez, I wish the city had better bus routes and times.\" → \"I think I could actually make headway on this problem with data!\"\n- **Collaboration:** \"Alice, I had this idea to try to find transportation data to improve the bus system in St. Paul.\" \"I love that idea! What are you thinking?\" I want students to develop an instinct to share their ideas with others and *crave* it. Like good news that balloons in your heart and comes out twice as fast and an octave higher than your normal speech. I also want them to be just as giddy hearing about others' ideas and become pro-feedback-givers: able to provide commentary that is thoughtful, actionable, and kind. And I want them to be pro-feedback-receivers: taking reactions with grace and humility.\n\nHow will I cultivate these habits?\n\n- **Inspiration and wonder:** I'm planning to give students pocket-sized \"noticing journals\" (like [these](https://smile.amazon.com/Notepads-Journal-Pocket-Notebooks-Colorful/dp/B09JYMXD6N)) to record their musings. I'll use writing prompts both in and out of class to encourage students to \"run\" with their wonders with a statistical mindset. Students will be encouraged to note ~2 musings weekly to be prepared for group discussions.\n- **Collaboration:** Group discussions will sustain those \"runs.\" With the thoughtful, actionable, and kind feedback of others, students can clarify a data collection and or analysis plan to investigate their curiosities or head down a different path and begin the process anew.\n\nHow does all of this fit in with \"regular\" learning?\n\n- The \"traditional\" stuff will still be there. I'll still use concept-centered learning objectives and many of the same materials (videos, readings) and learning activities that I have before. I just have to do a little adjustment to allocate regular class time to feedback (likely 15-20 minutes once per week in a course that meets 3 times/week for an hour).\n- The goal of the weekly musings and group discussions is primarily to cultivate habits (viewing the world statistically and practicing active listening), but it also lends itself to an authentic project experience. In the past, I've taught courses with either a monolithic semester-long project or a rushed project in the last 3 weeks of the course. These have forced students to choose topics too quickly, with a preference for ease, and without genuine interest. In contrast, a habitual approach to noticing and directed wondering should hopefully promote a deeper connection and sense of ownership with the project experience: the application area is chosen through \"ambient\" experience and affirmed with the feedback of others.\n\nI want students to engage meaningfully with their learning, and I want them to know that how they *feel* about their learning journey is *directly my top goal*. If I can address the *feeling* of learning well, then I expect that the more \"traditional\" conceptual learning will come more easily. I *need* to and *will* try. Cowabunga!\n","lastmodified":"2022-12-08T21:09:07.526176752Z","tags":null},"/Adapting-education-style-to-improve-relevance-and-practical-skills":{"title":"Adapting education style to improve relevance and practical skills","content":"\nPart of my educational duties this past semester was as a teaching assistant for an undergraduate introductory biostatistics course. We went over the usual topics—calculating probabilities from tables, test statistics, hypothesis testing, linear and logistic regression—and I felt that the curriculum made a great effort to contextualize the material by organizing the content into goal-oriented modules. For example, linear regression was introduced as a tool for the specific goal of explaining college students’ GPA based on alcohol consumption-related characteristics. Whether or not the dataset that we gave to the students was the best source of information for investigating this relationship, I felt that there were two pedagogical ideas behind this module that were well implemented. First, the relationship being explored (I would guess) is one that piques the interest of a large percentage of the students. A lot of college students drink and almost everyone knows someone who drinks. It was great that the theme for this module was self-motivating. Second, the structure of the main assignment for the module forced students to write in a substantive way. The students had to come up with their own linear regression models to explore the relationship between GPA and drinking-related characteristics, and they were asked to write a report of their process, findings, and model interpretations—all things that are essential to understand when reading, writing, and discussing research findings.\n\nI want to focus on these two teaching ideas for a bit and give my perspective on what we might need to do to adapt education for the future. Current events have precipitated a lot of intense and particularly emotion-backed discussion about racial injustice and inequality in general. From discussions with people much more knowledgeable and well-spoken than I am, I would have to say that perhaps the most essential asset that a lot of people don’t get from their education is an ability to think critically and argue rationally. These are hard things to do, and I think that school is the place to get people to practice.\n\nAs I’ve explained in previous posts, case-based learning is a great way to motivate the concepts being taught in class so that students can see their practical uses and therefore remember the ideas for the long-term. In creating examples and giving context to classroom content, we need to think hard about what those examples will be. Perhaps the best way to really engage students and get them to care about what they’re learning is to use the most current issues possible. For example, I think that someone who decided to create a case-based statistics course for the current generation might have a lot of success using both news and research articles about social inequality. I think the key is to relate what is being presented in the news to what research has actually been performed and get students to closely examine the relationship between these sources of information.\n\nRational argumentation is another skill that is lacking in our generation. Very often we tend to talk to and become friends with like-minded people, and we are not as easily forced to question our views and see fallacies in the bases for our opinions. Forcing conversation in an educational setting is a great way to break that comfort zone because there is such a diversity of opinion. I love that the statistics course that I taught for emphasized writing because it forced students to at least put some words behind what they were learning. Just having those words is several steps above rote calculation and memorization in terms of really embedding meaning and understanding. But the way to truly make the most of those words is to construct them carefully to tell a story, to make a point. Words as a list of facts do little to reinforce understanding. To this end, I think that educators should elevate the role of writing to the level of speech and debate. I see this having great potential in mathematics and statistics classrooms. Throughout a statistics course we teach students about tools and the assumptions behind them that are used to draw conclusions from data. To truly assess their understanding of statistical concepts and to put these concepts in a meaningful context, perhaps one of the key assignments or activities of the course would be to read scientific papers and have a debate. In this way, we can prepare students for the types of discussions that they’ll have throughout their life by helping them recognize reasoning flaws in the arguments of others as well as their own.\n","lastmodified":"2022-12-08T21:09:07.526176752Z","tags":null},"/Coach-dont-just-teach":{"title":"Coach, don't just teach","content":"\nOver the course of a 7 hour conversation, one woman changed the course of my marriage, yet she spoke for only 30 minutes.\n\nShe was a marriage therapist. But in many ways she felt like a coach.\n\n*How did you feel? Was it always that way? Say a little more.* With these simple nudges, she drew my gaze beyond the fresco of my marriage and helped me see the brushstrokes and the artists behind the stormy scarlets and blissful blues.\n\nIf a one-day therapy session could do so much for my marriage, why couldn't something similar be done for my students?\n\nStudents have always struggled in traditional classrooms due to commitments outside of school, inadequate preparation from prior teachers, heavy workloads, low motivation, and a rigid learning schedule. In the wake of the pandemic, [these struggles have become a crisis](https://www.nytimes.com/2022/11/01/us/covid-college-students.html) that has thrown both students and teachers into despair.\n\nWe've tried to respond with understanding without sacrificing our standards for meaningful learning. We've adopted policies that increase the flexibility of due dates. We've encouraged different types of assignments (e.g., written vs. oral). We've revamped our grading systems.\n\nUltimately, we've just applied Band-Aids.\n\nStudents struggling the most will continue to do so despite this flexibility. In order to truly help these students succeed and see beauty in learning, we need to reframe our roles as educators.\n\nWe need to become coaches.\n\nCoaches are expert listeners, question askers, and advocates. As teachers, we are experts in our disciplines and skilled at guiding students through concepts. But if students are like aspiring painters, it is not enough to simply provide instruction on how to mix colors and choose a brush (still crucial!). We need to also help them build their own frameworks for getting back to the easel even when they don't feel inspired to paint or after life gets in the way.\n\nLet's [broaden our perspective](https://smile.amazon.com/Range-Generalists-Triumph-Specialized-World-ebook/dp/B07H1ZYWTM) and learn more about what it takes to be a great coach.\n\nOne small change that I'm already planning to adopt is to ask better open-ended questions in 1-on-1 conversations with students to better understand the root cause of their struggles. The potential impact is immense: I already have many of these conversations in individual meetings or office hours. But I now know that by learning coaching skills, I can do much more than just re-explain concepts and give general study advice. *What are you struggling with? What went through your mind when you tried...? Why is that? Tell me more.*\n\nLong term, I'm sure that the following resources will be game-changers:\n\n- Corey Wilks' [World-Class Coaching course](https://coreywilkspsyd.mykajabi.com/world-class-coaching)\n- Saundra Yancy McGuire's book *[Teach Students How to Learn](https://smile.amazon.com/Teach-Students-How-Learn-Metacognition/dp/162036316X)*\n\nMy day-long marriage therapy session was not a magic paintbrush: problems still arise, and working through them is still challenging. But the coaching-like guidance that we received that day has reminded us to leave the studio door open: there, a lush landscape remains unfinished, and we can continue with our brushstrokes when we're ready.\n\nEducators, the benefits of coaching will take time to fully surface, especially as we learn to take on this new role. But every step our students take back towards their palettes will be a stunning stroke on our canvases. \n\n---\n\n*I am grateful to [Tobi Emonts-Holley](Tobisblog.uk), [Chris Cordry](chriscordry.com), [Corey Wilks](https://coreywilkspsyd.com/), [Hesam Panahi](https://hes.am/), [Jeremy Nguyen](https://twitter.com/RunGreatClasses), and [Sairam Sundaresan](https://www.artofsaience.com/) for their wonderful feedback on this piece.*\n","lastmodified":"2022-12-08T21:09:07.526176752Z","tags":null},"/Dungeons-and-Dragons-Web-Scraping-with-rvest-and-RSelenium":{"title":"Dungeons and Dragons Web Scraping with rvest and RSelenium","content":"\nI love Dungeons and Dragons. I am also a data-loving statistician. At some point, these worlds were bound to collide.\n\nFor those unfamiliar with Dungeons and Dragons (DnD), it is a role-playing game that is backed by an extraodinary amount of data. The overall gist is that players create characters that band together with other characters to travel the world and adventure. Essentially, it's collective storytelling aided by dice as vehicles of chance and uncertainty. Where does data come in? Through the world-building content that is released by the official creators and by players. This content helps players build characters that have a range of characteristics and abilities governed by their past and occupation. This content similarly helps shape the monsters and enemies that the characters may face.\n\nThere is a wonderful digital resource for DnD content called [DnD Beyond](https://www.dndbeyond.com/) that contains information on characters, monsters, and treasures. (No API yet, but it is apparently [in the works](https://twitter.com/dndbeyond/status/909834529736740864?lang=en).) For a while, I've been interested in playing around with data on monster statistics, and I finally got around to it this week! I had been reluctant to start because I did not have a clear idea of how to scrape pages that required login via redirect to an external authentication service (here, Twitch). I'll go over the specific hurdles and solutions in this post. I'll also give a general tutorial for scraping with `rvest`.\n\nAll of the code for this post is available at https://github.com/lmyint/dnd_analysis.\n\n# Structure of the scraping task\n\nIf you go to https://www.dndbeyond.com/monsters, you will see the first of several tens of pages of monster listings. You will also see that each monster name is a link to an individual monster page that contains more extensive details about that monster's statistics, abilities, and lore. An example that is free to view is the [Adult Green Dragon](https://www.dndbeyond.com/monsters/adult-green-dragon). Other monsters that are not part of the Basic Rules set can only be viewed if you are signed in and have purchased the digital book in which that monster is contained.\n\nThe first part of the scraping task is to the scrape the several pages of tables starting at https://www.dndbeyond.com/monsters in order to get the links to individual monster pages.\n\nThe second part of the scraping task is to scrape the individual monster pages, such as the [Adult Green Dragon](https://www.dndbeyond.com/monsters/adult-green-dragon).\n\nThroughout, I use the following packages:\n\n- [rvest](https://cran.r-project.org/web/packages/rvest/index.html) for page scraping\n- [stringr](https://cran.r-project.org/web/packages/stringr/index.html) for working with strings\n- [tibble](https://cran.r-project.org/web/packages/tibble/index.html) for the flexibility over data frames to allow list-columns\n- [RSelenium](https://github.com/ropensci/RSelenium) for browser navigation via R. This package was on CRAN but removed in May 2018. I used the development version on GitHub, but the package maintainer is [currently working to fix this](https://github.com/ropensci/RSelenium/issues/172).\n\n# Step 1: Scrape tables to get individual monster page URLs\n\nBy visiting a few different pages of monster results, we can see that the URLs for the page results have a consistent format: `https://www.dndbeyond.com/monsters?page=NUM` where `NUM` ranges from 1 to the last page. We can obtain the last page number programatically with the following:\n\n```r\npage \u003c- read_html(\"https://www.dndbeyond.com/monsters\")\nnum_pages \u003c- page %\u003e%\n\thtml_nodes(\".b-pagination-item\") %\u003e%\n\thtml_text() %\u003e%\n\tas.integer() %\u003e%\n\tmax(na.rm = TRUE)\n```\n\nLet's explore the anatomy of this code to better understand how to work with `rvest`.\n\n## General structure of `rvest` code\n\nThe small example above shows the power of `rvest`. In many cases, the code to scrape content on a webpage really does boil down to something as short as:\n\n```\nurl %\u003e% read_html() %\u003e% html_nodes(\"CSS or XPATH selector\") %\u003e% html_text() OR html_attr()\n```\n\n- We start with a URL string that is passed to the `read_html` function. This creats an XML document object which is a tree representation of the content on a webpage. Why a tree? This requires some familiarity with HTML, but essentially text content is nested within enclosing formatting tags to make up a webpage. The following diagram from a [W3Schools tutorial](https://www.w3schools.com/js/js_htmldom_navigation.asp) illustrates this.\n![](https://www.w3schools.com/js/pic_htmltree.gif)\n\n- The `html_nodes` function takes a string specifying the HTML tags that you desire to be selected. The selector string can be a CSS or XPATH selector. I only know about CSS selectors, and that has sufficed for all of my web scraping to date. This function returns a list of nodes that have been selected from the HTML tree. For example, selecting the `\u003cbody\u003e` tag is like grabbing the trunk of the HTML tree, and selecting paragraph `\u003cp\u003e` tags is like grabbing only the thinner branches. This list of nodes is still a list of XML objects.\n\n- Usually what we want in scraping is the text that we see on the webpage that is contained within the specific sections extracted with `html_nodes`. We can get this text with `html_text`. Often we will also want attributes of the text on a webpage. For example, we may see text that is actually a link, and we want the URL for that link. In this case `html_text` would not give us what we want because it would give us the link text. However, `html_attr` will allow us to extract the URL. A specific example of this in just a second!\n\n## SelectorGadget\n\nBack to the code example above:\n\n```r\npage \u003c- read_html(\"https://www.dndbeyond.com/monsters\")\nnum_pages \u003c- page %\u003e%\n\thtml_nodes(\".b-pagination-item\") %\u003e%\n\thtml_text() %\u003e%\n\tas.integer() %\u003e%\n\tmax(na.rm = TRUE)\n```\n\nThe most difficult part of this part of code is figuring out the selector to use in `html_nodes`. Luckily, the `rvest` package page on CRAN has a link to a vignette on a tool called [SelectorGadget](https://cran.r-project.org/web/packages/rvest/vignettes/selectorgadget.html). I love this tool for its playful homage to [childhood memories](https://www.youtube.com/watch?v=e-JHfXVlkik), and it also greatly helps in determining the CSS selectors needed to select desired parts of a webpage. Once you have dragged the tool link to the bookmark bar, you can click the bookmark while viewing any page to get a hover tool that highlights page elements as you mouse over them. Clicking on an element on the page displays the text for the CSS selector in the tool panel.\n\nUsing the SelectorGadget tool, we can determine that the page number buttons on the [main monster page](https://www.dndbeyond.com/monsters) all have the class `b-pagination-item`. The CSS selector for a class always starts with a period followed by the class name. The last page was the maximum of these numbers. (We need to remove `NA`'s created by integer coercion of the \"Next\" button.)\n\n## Extract URLs\n\nNow that we know how many pages (`num_pages`) to loop through, let's write a function that will extract the URLs for the individual monster pages that are present on a single page of results.\n\n```r\nget_monster_links \u003c- function(url) {\n\tpage \u003c- read_html(url)\n\trel_links \u003c- page %\u003e%\n\t\thtml_nodes(\".link\") %\u003e%\n\t\thtml_attr(name = \"href\")\n\tkeep \u003c- str_detect(rel_links, \"/monsters/\")\n\trel_links \u003c- rel_links[keep]\n\tabs_links \u003c- paste0(\"https://www.dndbeyond.com\", rel_links)\n\tabs_links\n}\n```\n\nThe `get_monster_links` function takes as input a URL for a page of results (like https://www.dndbeyond.com/monsters?page=2). Let's work through the function body:\n\n- We first read the HTML source of a page with `read_html`.\n- We can then use a combination of SelectorGadget with the \"View page source\" functionality of your browser to select the links on the page. Here we find that they belong to class `link`.\n- We use the `html_attr` function here to extract the link path rather than the link text. The `name = \"href\"` specifies that we want the path attribute. (Anatomy of an HTML link: `\u003ca href=\"https://www.something.com\"\u003eLink text seen on page\u003c/a\u003e`).\n- The remainder of the function subsets the extracted links to only those that pertain to the monster pages (removing links like the home page). Printing the output indicates that these links are only relative links, so we append the base URL to create absolute links (`abs_links`).\n\nFinally, we can loop through all pages of results to get the hundreds of pages for the individual monsters:\n\n```r\n## Loop through all pages\nall_monster_urls \u003c- lapply(seq_len(num_pages), function(i) {\n\turl \u003c- paste0(\"https://www.dndbeyond.com/monsters?page=\", i)\n\tget_monster_links(url)\n}) %\u003e% unlist\n```\n\n# Step 2: Use `RSelenium` to access pages behind login\n\nIn Step 1, we looped through pages of tables to get the URLs for pages that contain detailed information on individual monsters. Great! We can visit each of these pages and just do some more `rvest` work to scrape the details! Well... not immediately. Most of these monster pages can only be seen if you have paid for the corresponding digital books and are logged in. DnD Beyond uses [Twitch](https://www.twitch.tv/) for authentication which involves a redirect. This redirect made it way harder for me to figure out what to do. It was like I had been thrown into the magical, mysterious, and deceptive realm of the [Feywild](http://forgottenrealms.wikia.com/wiki/Feywild) where I frantically invoked Google magicks to find many dashed glimmers of hope but luckily a solution in the end.\n\n## What did not work\n\nIt's helpful for me to record what things I tried and failed so I can remember my thought process. Hopefully, it saves you wasted effort if you're ever in a similar situation.\n\n- Using `rvest`'s page navigation abilities did not work. I tried the following code:\n\n```r\nurl \u003c- \"https://www.dndbeyond.com/login\"\nsession \u003c- html_session(url)\nurl \u003c- follow_link(session, \"Login\")\n```\n\nBut I ran into an error:\n\n```\nError in curl::curl_fetch_memory(url, handle = handle) : \n  Could not resolve host: NA\n```\n\n- Using `rvest`'s basic authentication abilities did not work. I found [this tutorial](https://github.com/rstudio/webinars/blob/master/32-Web-Scraping/navigation-and-authentication.md) on how to send a username and password to a form with `rvest`. I tried hardcoding the extremely long URL that takes you to a Twitch authentication page, sending my username and password as described in the tutorial, and following [this Stack Overflow suggestion] to create a fake login button since the authentication page had an unnamed, unlabeled \"Submit\" input that did not seem to conform to `rvest`'s capabilities. I got a 403 error.\n\n## What did work\n\nOnly when I stumbled upon this [Stack Overflow post](https://stackoverflow.com/questions/40198182/403-error-when-using-rvest-to-log-into-website-for-scraping) did I learn about the `RSelenium` package. [Selenium](https://www.seleniumhq.org/) is a tool for automating web browsers, and the `RSelenium` package is the R interface for it.\n\nI am really grateful to the posters on that Stack Overflow question and [this blog post](https://abdallaabdi.com/2016/02/13/navigating-scraping-job-sites-rvest-rselenium/) for getting me started with `RSelenium`. The only problem is that the `startServer` function used in both posts is now defunct. When calling `startServer`, the message text informs you of the `rsDriver` function.\n\n### Step 2a: Start automated browsing with `rsDriver\n\nThe amazing feature of the `rsDriver` function is that you do not need to worry about downloading and installing other sofware like Docker or phantomjs. This function works right out of the box! To start the automated browsing, use the following:\n\n```r\nrd \u003c- rsDriver(browser = \"chrome\")\nrem_dr \u003c- rd[[\"client\"]]\n```\n\nWhen you first run `rsDriver`, status messages will indicate that required files are being downloaded. After that you will see the status text \"Connecting to remote server\" and a Chrome browser window will pop open. The browser window will have a message beneath the search bar saying \"Chrome is being controlled by automated test software.\" This code comes straight from the example in the `rsDriver` help page.\n\n### Step 2b: Browser navigation and interaction\n\nThe `rem_dr` object is what we will use to navigate and interact with the browser. This navigation and interaction is achieved by accessing and calling functions that are part of the `rem_dr` object. We can navigate to a page using the `$navigate()` function. We can select parts of the webpage with the `$findElement()` function. Once these selections are made, we can interact with the selections by\n\n- Sending text to those selections with `$sendKeysToElement()`\n- Sending key presses to those selections with `$sendKeysToElement()`\n- Sending clicks to those selections with `$clickElement()`\n\nAll of these are detailed in the [RSelenium Basics vignette](http://rpubs.com/johndharrison/RSelenium-Basics), and further examples are in the [Stack Overflow](https://stackoverflow.com/questions/40198182/403-error-when-using-rvest-to-log-into-website-for-scraping) and [blog post](https://abdallaabdi.com/2016/02/13/navigating-scraping-job-sites-rvest-rselenium/) I mentioned above.\n\nThe code below shows this functionality in action:\n\n```r\nurl \u003c- \"https://www.dndbeyond.com/login\"\nrem_dr$navigate(url) # Navigate to login page\nrem_dr$findElement(using = \"css selector\", value = \".twitch-button\")$clickElement() # Click the \"Login with Twitch\" button\n## Manually enter username and password here\nrem_dr$findElement(using = \"css selector\", value = \".js-authorize-text\")$clickElement() # Click the \"Authorize\" button to continue logging in\n```\n\nNote: Once the Chrome window opens, you can finish the login process programatically as above or manually interface with the browser window as you would normally. This can be safer if you don't want to have a file with your username and password saved anywhere.\n\n### Step 2c: Extract page source\n\nNow that we have programatic control over the browser, how do we interface with `rvest`? Once we navigate to a page with `$navigate()`, we will need to extract the page's HTML source code to supply to `rvest::read_html`. We can extract the source with `$getPageSource()`:\n\n```r\nrem_dr$navigate(url)\npage \u003c- read_html(rem_dr$getPageSource()[[1]])\n```\n\nThe subset ``[[1]]`` is needed after calling `rem_dr$getPageSource()` because `$getPageSource()` returns a list of length 1. The HTML source that is read in can be directly input to `rvest::read_html`.\n\nExcellent! Now all we need is a function that scrapes the details of a monster page and loop! In the following, we put everything together in a loop that iterates over the vector of URLs (`all_monster_urls`) generated in Step 1.\n\nWithin the loop we call the custom `scrape_monster_page` function to be discussed below in Step 3. We also include a check for purchased content. If you try to access a monster page that is not part of books that you have paid for, you will be redirected to a new page. We perform this check with the `$getCurrentUrl()` function, filling in a missing value for the monster information if we do not have access. The `Sys.sleep` at the end can be useful to avoid overloading your computer or if rate limits are a problem.\n\n```r\nmonster_info \u003c- vector(\"list\", length(all_monster_urls))\nfor (i in seq_along(all_monster_urls)) {\n\turl \u003c- all_monster_urls[i]\n\trem_dr$navigate(url)\n\tpage \u003c- read_html(rem_dr$getPageSource()[[1]])\n\t## If content has not been unlocked, the page will redirect\n\tcurr_url \u003c- rem_dr$getCurrentUrl()[[1]]\n\tif (curr_url == url) {\n\t\tmonster_info[[i]] \u003c- scrape_monster_page(page)\n\t} else {\n\t\tmonster_info[[i]] \u003c- NA\n\t}\n\tSys.sleep(2)\n\tcat(i, \" \")\n}\n```\n\n# Step 3: Write a function to scrape an individual page\n\nThe last step in our scraping endeavor is to write the `scrape_monster_page` function to scrape data from an individual monster page. You can view the full function [on GitHub](https://github.com/lmyint/dnd_analysis/blob/master/scrape_monster_stats.R). I won't go through every aspect of this function here, but I'll focus on some principles that appear in this function that I've found to be useful in general when working with `rvest`.\n\n## Principle 1: Use SelectorGadget AND view the page's source\n\nAs useful as SelectorGadget is for finding the correct CSS selector, I never use it alone. I always open up the page's source code and do a lot of Ctrl-F to quickly find specific parts of a page. For example, when I was using SelectorGadget to get the CSS selectors for the Armor Class, Hit Points, and Speed attributes, I saw the following:\n\n![](/post/2018-08-10-dnd-scraping_files/attr_block.png)\n\nI wanted to know if there were further subdvisions of the areas that the `.mon-stat-block__attribute` selector had highlighted. To do this, I searched the source code for \"Armor Class\" and found the following:\n\n```html\n\u003cdiv class=\"mon-stat-block__attribute\"\u003e\n    \u003cspan class=\"mon-stat-block__attribute-label\"\u003eArmor Class\u003c/span\u003e\n    \u003cspan class=\"mon-stat-block__attribute-value\"\u003e\n        \u003cspan class=\"mon-stat-block__attribute-data-value\"\u003e\n            19\n        \u003c/span\u003e\n        \n            \u003cspan class=\"mon-stat-block__attribute-data-extra\"\u003e\n                (Natural Armor)  \n            \u003c/span\u003e \n                 \n    \u003c/span\u003e\n\u003c/div\u003e\n\u003cdiv class=\"mon-stat-block__attribute\"\u003e\n    \u003cspan class=\"mon-stat-block__attribute-label\"\u003eHit Points\u003c/span\u003e\n    \u003cspan class=\"mon-stat-block__attribute-data\"\u003e\n        \u003cspan class=\"mon-stat-block__attribute-data-value\"\u003e\n            207\n        \u003c/span\u003e\n        \u003cspan class=\"mon-stat-block__attribute-data-extra\"\u003e\n            (18d12 + 90)\n        \u003c/span\u003e      \n    \u003c/span\u003e\n\u003c/div\u003e\n\u003cdiv class=\"mon-stat-block__attribute\"\u003e\n    \u003cspan class=\"mon-stat-block__attribute-label\"\u003eSpeed\u003c/span\u003e\n    \u003cspan class=\"mon-stat-block__attribute-data\"\u003e\n        \u003cspan class=\"mon-stat-block__attribute-data-value\"\u003e\n            40 ft., fly 80 ft., swim 40 ft.\n             \n        \u003c/span\u003e\n    \u003c/span\u003e\n\u003c/div\u003e\n```\n\nLooking at the raw source code allowed me to see that each line was subdivided by spans with classes `mon-stat-block__attribute-label`, `mon-stat-block__attribute-data-value`, and sometimes `mon-stat-block__attribute-data-extra`.\n\nWith SelectorGadget, you can actually type a CSS selector into the text box to highlight the selected parts of the page. I did this with the `mon-stat-block__attribute-label` class to verify that there should be 3 regions highlighted.\n\n![](/post/2018-08-10-dnd-scraping_files/attr_label.png)\n\nBecause SelectorGadget requires hovering your mouse over potentially small regions, it is best to verify your selection by looking at the source code.\n\n## Principle 2: Print often\n\nContinuing from the above example of desiring the Armor Class, Hit Points, and Speed attributes, I was curious what I would obtain if I simply selected the whole line for each attribute (as opposed to the three subdivisions). The following is what I saw when I printed this to the screen:\n\n```\n\u003e page %\u003e% html_nodes(\".mon-stat-block__attribute\") %\u003e% html_text()\n[1] \"\\n            Armor Class\\n            \\n                \\n                    19\\n                \\n                \\n                    \\n                        (Natural Armor)  \\n                     \\n                         \\n            \\n        \"\n[2] \"\\n            Hit Points\\n            \\n                \\n                    207\\n                \\n                \\n                    (18d12 + 90)\\n                      \\n            \\n        \"                                                         \n[3] \"\\n            Speed\\n            \\n                \\n                    40 ft., fly 80 ft., swim 40 ft.\\n                     \\n                \\n            \\n        \"\n```\n\nA mess! A length-3 character vector containing the information I wanted but not in a very tidy format. Because I want to visualize and explore this data later, I want to do a little tidying up front in the scraping process.\n\nWhat if I just access the three subdivisions separately and `rbind` them together? This is not a good idea because of missing elements as shown below:\n\n```\n\u003e page %\u003e% html_nodes(\".mon-stat-block__attribute-label\") %\u003e% html_text()\n[1] \"Armor Class\" \"Hit Points\"  \"Speed\"      \n\u003e page %\u003e% html_nodes(\".mon-stat-block__attribute-data-value\") %\u003e% html_text() %\u003e% trimws()\n[1] \"19\"                              \"207\"                            \n[3] \"40 ft., fly 80 ft., swim 40 ft.\"\n\u003e page %\u003e% html_nodes(\".mon-stat-block__attribute-data-extra\") %\u003e% html_text() %\u003e% trimws()\n[1] \"(Natural Armor)\" \"(18d12 + 90)\"\n```\n\nFor `attribute-label`, I get a length-3 vector. For `attribute-data-value`, I get a length-3 vector. For `attribute-data-value`, I only get a length-2 vector! Through visual inspection, I know that the third line \"Speed\" is missing the span with the `data-extra` class, but I don't want to rely on visual inspection for these hundreds of monsters! **Printing these results warned me directly that this could happen!** Awareness of these missing items motivates the third principle.\n\n## Principle 3: You will need loops\n\nFor the Armor Class, Hit Points, and Speed attributes, I wanted to end up with a data frame that looks like this:\n\n```\n\u003e attrs\n# A tibble: 3 x 3\n  label       value                           extra          \n  \u003cchr\u003e       \u003cchr\u003e                           \u003cchr\u003e          \n1 Armor Class 19                              (Natural Armor)\n2 Hit Points  207                             (18d12 + 90)   \n3 Speed       40 ft., fly 80 ft., swim 40 ft. NA\n```\n\nThis data frame has properly encoded missingness. To do this, I needed to use a loop as shown below.\n\n```r\n## Attributes: AC, HP, speed\nattr_nodes \u003c- page %\u003e%\n\thtml_nodes(\".mon-stat-block__attribute\")\nattrs \u003c- do.call(rbind, lapply(attr_nodes, function(node) {\n\tlabel \u003c- node %\u003e%\n\t\tselect_text(\".mon-stat-block__attribute-label\")\n\tdata_value \u003c- node %\u003e%\n\t\tselect_text(\".mon-stat-block__attribute-data-value\")\n\tdata_extra \u003c- node %\u003e%\n\t\tselect_text(\".mon-stat-block__attribute-data-extra\") %\u003e%\n\t\treplace_if_empty(NA)\n\ttibble(label = label, value = data_value, extra = data_extra)\n}))\n```\n\nThe code below makes use of two helper functions that I wrote to cut down on code repetition:\n\n- `select_text` to cut down on the repetitive `page %\u003e% html_nodes %\u003e% html_text`\n\n```r\nselect_text \u003c- function(xml, selector, trim = TRUE) {\n\ttext \u003c- xml %\u003e% \n\t\thtml_nodes(selector) %\u003e%\n\t\thtml_text\n\tif (trim) {\n\t\ttext \u003c- text %\u003e%\n\t\t\ttrimws\n\t}\n\ttext\n}\n```\n\n- `replace_if_empty` to repace empty text with `NA`\n\n```r\nreplace_if_empty \u003c- function(text, to) {\n\tif (length(text)==0) {\n\t\ttext \u003c- to\n\t}\n\ttext\n}\n```\n\nI first select the three lines corresponding to these three attributes with\n\n```r\nattr_nodes \u003c- page %\u003e%\n\thtml_nodes(\".mon-stat-block__attribute\")\n```\n\nThis creates a list of three nodes (pieces of the webpage/branches of the HTML tree) corresponding to the three lines of data:\n\n```\n\u003e attr_nodes\n{xml_nodeset (3)}\n[1] \u003cdiv class=\"mon-stat-block__attribute\"\u003e\\n            \u003cspan class=\"mon-sta ...\n[2] \u003cdiv class=\"mon-stat-block__attribute\"\u003e\\n            \u003cspan class=\"mon-sta ...\n[3] \u003cdiv class=\"mon-stat-block__attribute\"\u003e\\n            \u003cspan class=\"mon-sta ...\n```\n\n**We can chain together a series of calls to `html_nodes`.** I do this in the subsequent `lapply` statement. I know that each of these nodes contains up to three further subdivisions (label, value, and extra information). In this way I can make sure that these three pieces of information are aligned between the three lines of data.\n\nNearly all of the code in the `scrape_monster_page` function repeats these three principles, and I've found that I routinely use similar ideas in other scraping I've done with `rvest`.\n\n# Summary\n\nThis is a long post, but a few short take-home messages suffice to wrap ideas together:\n\n- `rvest` is remarkably effective at scraping what you need with fairly concise code. Following the three principles above has helped me a lot when I've used this package.\n- `rvest` can't do it all. For scraping tasks where you wish that you could automate clicking and typing in the browser (e.g. authentication settings), `RSelenium` is the package for you. In particular, the `rsDriver` function works right out of the box (as far as I can tell) and is great for people like me who are loath to install external dependencies.\n\nHappy scraping!\n","lastmodified":"2022-12-08T21:09:07.526176752Z","tags":null},"/Fight-every-battle-everywhere-this-is-science":{"title":"Fight every battle everywhere: this is science","content":"\nI love Game of Thrones. I particularly liked this mini-speech from Petyr Baelish earlier in Season 7:\n\n\u003e Don’t fight in the North or the South. Fight every battle everywhere, always, in your mind. Everyone is your enemy, everyone is your friend. Every possible series of events is happening all at once. Live that way and nothing will surprise you. Everything that happens will be something that you’ve seen before.\n\nAs I let my mind wander away from work for a bit today, I realized that this is a wonderful quote about science!\n\n## Fight every battle everywhere, always, in your mind\n\nBaelish is a shrewd, obsessive planner. In planning for everything that could possibly happen, he always seems to be prepared, get what he wants, and stay alive. Just like staying alive in Westeros in positions of power, doing good science can be quite difficult because we are set adrift in extremely complex systems. There are so many paths that that can be followed to answer a research question (including the formulation of the question itself!), and all could be the subject of an intellectual battle with a critic. Studying the effect of yearly bonuses for teachers on long-term student outcomes? How do you define long-term? What outcomes will you measure and how? How will you prevent dropout? How do you make differing bonus amounts comparable for teachers who differ in terms of what they teach, where they live, what composition of students they teach from year to year? How would you even define \"composition of students\"? Also why study student outcomes as opposed to community outcomes? There is no way that a single study could address all of these concerns, or the ones that I couldn't think of, but these concerns need to be thought about because they need to be _answered_ for us to have any hope of meaningful, actionable conclusions. Just the act of forecasting these hypothetical intellectual battles can motivate the design of better studies.\n\n## Everyone is your enemy, everyone is your friend\n\nBaelish is calculating and knows how effective people can be in various contexts. It can be helpful to think of everyone in the scientific community as your enemy—enemies ready to question every aspect of your work and find every possible hole—but only if it indeed motivates _you_ to do those very things. Only by heavily scrutinizing our own work can we make ourselves the best scientists possible. Acknowledging limitations in private and subsequently making them known to others is key to moving the state of knowledge forward. I do want to de-emphasize any paranoid or hateful connotations of this quote though! Some people in my field take the \"everyone is your enemy\" part too seriously and critique others in inflammatory ways.\n\nNow the friends part...this probably works out better for science than for Baelish. Scientists form a community, and ideally [sharing everything](https://simplystatistics.org/2015/12/11/instead-of-research-on-reproducibility-just-do-reproducible-research/) about our work would facilitate a team effort to find even more limitations and address them fruitfully to get leaps and bounds closer to useful answers. But my impression is that things generally don't happen this way. Groups work somewhat in isolation on different aspects of a problem. Perhaps consortia try to harmonize efforts in some respects, but useful information is still needed from external sources and not able to be integrated easily. Just as it is hard in Westeros to find good allies, it can be difficult in science to find good collaborators. But when it does happen, great deeds are in the works.\n\n## Every possible series of events is happening all at once\n\nIn Westeros, livelihoods dance on the whims of nobles and on the breath of armies that can be traded with coin coffers or decimated in an afternoon. This creates a palpable urgency for Baelish to always stay ahead of the game. This immediacy isn't really felt in science. We don't gamble with our lives when we submit a paper and wait for the review process to unfold. I think that the scientific community is lured to progress slowly with our [recognition system](http://www.sciencemag.org/news/2015/12/got-just-single-observation-new-journal-will-publish-it) favoring large numbers of publications. Researchers who have large projects are incentivized to break the project up into several publications. I don't think this is necessarily bad if the scientists have actually completed this larger body of research. The flaw I see is if it incentivizes scientists to publish work that isn't as complete out of time pressure and fail to follow up with more complete validation because they feel the validation work isn't \"enough\" for its own publication. There is [some effort to recognize replication attempts](http://www.sciencemag.org/news/2016/02/if-you-fail-reproduce-another-scientist-s-results-journal-wants-know), but I wish that there were more urgency and incentive to conduct more complete studies the first time around because it sets the baseline higher for future work.\n","lastmodified":"2022-12-08T21:09:07.526176752Z","tags":null},"/Grading-doesnt-have-to-suck":{"title":"Grading doesn't have to suck","content":"\nGrading doesn't have to suck—for teachers or for students. Two books on grading have inspired me to adopt a reinvigorated mindset towards grading and feedback: *Specifications Grading* by Linda Nilson and *Grading for Equity* by Joe Feldman. In this post, I want to summarize key ideas from both books and share my thought process for course preparation that incorporates the essential parts of both frameworks.\n\n## Why change grading systems? The beast that is traditional grading\n\nUntil recently, I used a traditional points-based grading system in my courses: points for homework, exams, and projects, all under some weighting scheme to determine the overall course grade. Grading always brought about negative emotions for me at every stage of the process—the anticipation of it, the act of actually doing it, and reflecting on grades that I had assigned. This negativity generally stemmed from five sources:\n\n- Grading always took up so much time.\n- Disputes with students about points were always disheartening.\n- I was disappointed that grades sometimes reflected students' understanding poorly—both overestimating and underestimating their understanding.\n- I was disappointed at seeing the same mistakes over and over again.\n- I was worried about the stress that my students were feeling.\n\nOut of habit I dismissed these woes as necessary evils of my job, but after reading *Specifications Grading* and *Grading for Equity*, I've felt inspired to reach for something better. In the next two sections, I'll summarize the specifications and equity grading frameworks. I'll end with some course preparation thoughts that combine both frameworks.\n\n## Specifications Grading\n\n### Two key components: specs and rubrics\n\nA **specification** (or **spec** for short) is a requirement that an instructor sets for a piece of student work. In a specifications grading system, all assessments of course learning objectives have a set of specs that are each graded on a pass/fail scale. For a given assessment, **all** specs must be passed in order for the assignment as a whole to receive a passing grade. With this pass/fail evaluation, it is essential that instructors provide a very clear rubric of what it means to earn a pass for a given spec. For example, I might ask students to create a captioned data visualization that shows the relationship between two variables in a dataset. The specs and rubrics for a passing grade could be as follows:\n\n- Spec 1: Visualization must be correct and well-labeled.\n    - Rubric: Visualization must...\n        - Be the appropriate type for the given variables\n        - Have axis labels with units and full words (as opposed to coded variable names)\n- Spec 2: Caption must correctly describe the visualization with appropriate numerical summary measures.\n    - Rubric: Caption must...\n        - Discuss the strength and direction of the relationship\n        - Use appropriate numerical summaries\n\n### Mapping assessment grades to course grades\n\nTo determine final course grades, instructors can link letter grades to desired combinations of passed assessments. For example, to earn an A students must pass 9 out of the 10 course assignments or must pass a specific set of the 10 assignments. This approach to determining a final course grade is called the **bundling approach**—bundles of passed assignments translate to a letter grade. (Another approach that assigns points to passed assessments is discussed in Chapter 6 of *Specifications Grading*. However, in alignment with the equity grading framework discussed later, I'm not an advocate of this **point system approach**.) The bundling approach has transparency advantages for both instructors and students. Instructors can look at a letter grade and know exactly what students understand. Students know exactly what they must to to earn a given letter grade.\n\n### Pros and cons of specs grading\n\nThe pass/fail grading of specifications and assessments (with sufficiently clear rubrics) is intended to produce the following benefits:\n\n- Saving time for teachers: The lack of partial credit avoids time-consuming deliberations over points.\n- Increasing rigor: Setting high standards for a pass encourages higher quality work than a points-based system with partial credit.\n- Increased consistency of grades between students: Rubrics for pass/fail grades should be resistant to biases that plague finer scales.\n- High clarity and transparency:\n    - For instructors: With bundling, a letter indicates exactly what students understand.\n    - For students: Rubrics and grade bundles tell students exactly what they need to do to succeed, which can motivate them to aim higher than they would have normally.\n\nSome potential downsides of specs grading include:\n\n- Writing sufficiently clear rubrics can be very time-consuming the first time. However, this initial time investment should translate to time savings during the course and its future offerings.\n- Students may be resistant to a new grading system without partial credit. Instructors will need to devote time to communicating why they are using a specs grading system.\n\nIn my opinion, the downsides of specs grading are well worth its benefits. As we'll see next, many of its benefits align with an equity-oriented grading framework.\n\n## Grading for Equity\n\n### Pillars of the framework\n\nAn equity grading system is rooted in three pillars:\n\n- **Grades must be mathematically accurate:** The final number or letter grade given to students must accurately reflect their understanding of course concepts by the end of the course.\n- **Grades must be bias-resistant:** As much as possible, grades must be free from the influence of the instructor's implicit biases and the student's life circumstances.\n- **Grades must be motivational:** Grades should inspire students to learn and excel.\n\nIn *Grading for Equity*, Joe Feldman proposes several concrete course policies that support these pillars. Throughout, he builds from the central tenet that **grades should accurately reflect students' understanding of course content and nothing else**. In the rest of this section, I'll summarize his proposed policies and how they connect to these three pillars.\n\n### Avoid assigning zeroes by using a minimum grading policy\n\nIn points-based grading systems, many instructors assign zero points to assessments that are late, incomplete, or fraudulent as a means of deterring and punishing undesirable behavior. A more equitable points-based system avoids assigning zeroes. One policy that Feldman proposes for this is **minimum grading**, which is a policy that assigns a standard nonzero grade (say, 40 out of 100 points) where the instructor would normally give a zero.\n\n- Pillar 1 (Mathematical accuracy): Particularly on 100 point scales, zeroes have a disproportionate effect on point averages that are commonly used to determine final grades. In this way, assigning zeroes substantially underestimates student understanding. Further, a zero is inherently dubious as it signals that a student has absolutely no knowledge of a topic, which is highly unlikely. Minimum grading can help rectify the sensitivity of grades to outlier zeroes.\n- Pillar 3 (Motivation): Seeing a zero can be utterly demotivating to a student. Often times, recovering from one or more zeroes requires an extraordinary amount of effort (if it is possible at all), and this can extinguish any flicker of a growth mindset. Minimum grading can help sustain student optimism.\n\nSince thinking about specifications grading frameworks, I'm not a fan of points-based grading systems, so I don't intend to use these the no-zero or minimum grading policies. However, I think they are worth considering for instructors who prefer points-based systems.\n\n### Use a 0-4 scale\n\nPoints-based grading systems often use 100-point or similarly fine-grained scales to evaluate student work. A coarser (e.g., 0-4) scale can help make grades more equitable.\n\n- Pillar 1 (Mathematical accuracy): Fine scales are subject to considerable variability. Even with a rubric, an instructor could easily reread the same work and assign slightly different scores each time. A coarse 0-4 scale promotes accuracy and consistency of grades.\n- Pillar 2 (Resistance to bias): Because scores given on fine scales have more room to vary, they are more subject to instructors' implicit biases. Coarser scales allow instructors to follow rubrics with greater consistency.\n\nThe 0-4 scale policy very closely aligns with the specifications grading approach. The specs grading approach takes coarse scales to the extreme by essentially proposing a 0-1 scale.\n\n### Weigh recent performance more than early performance\n\nTypically, instructors include all student attempts to show understanding of a concept in the course grade. Instead, they should weigh latest student performance more heavily. At the extreme, **only** the most recent assessments of a skill count toward the grade.\n\n- Pillar 1 (Mathematical accuracy): Grades should reflect student understanding of material by the end of the course—not how quickly students reached that level of understanding. Thus, it doesn't make sense to include grades for the early stage of the learning process. By weighing recent performance more heavily, grades more accurately reflect student understanding by the end of the course.\n- Pillar 2 (Resistance to bias): Students who have more difficult life circumstances might take longer to grasp concepts and would have lower grades under a traditional system that evaluates during the learning process. Weighing recent performance more heavily allows these struggling students the extra time they need to show the same level of understanding as their more privileged peers.\n- Pillar 3 (Motivation): Giving less weight to (and perhaps not even counting) early performance can inspire a growth mindset in students—particularly those who initially struggle. Without early struggles pulling the grade down, students can optimistically work toward genuine improvement.\n\nThis policy relates closely to a **retakes and redos** policy described later.\n\n### Avoid assigning grades for the product of group work\n\nInstead of grading the product of group work, instructors should evaluate students individually after the group work is complete.\n\n- Pillar 1 (Mathematical accuracy): Group work tends to reflect the work of the strongest group members. Applying the group grade to individual students will overestimate the understanding of struggling students. With this policy, students can still benefit from collaboration, but the grades assigned will actually reflect individual understanding.\n- Pillar 3 (Motivation): When students must demonstrate their learning individually, they are more motivated to do the necessary work than when falling back on group members is possible.\n\nIf group work is solely meant to provide enriching learning experiences for students, then the framework of [complex instruction](https://complexinstruction.stanford.edu/) is worth thinking about. I'll say a bit more about complex instruction at the end of the post.\n\n### Avoid incorporating extra credit into the grade\n\nInstructors award extra credit for a wide variety of activities. These activities can be course-related, but often times they are not. Extra credit violates all 3 pillars of equitable grading.\n\n- Pillar 1 (Mathematical accuracy): In the worst case that extra credit has nothing to do with course content (e.g., bringing in materials for the class), grades become a nonsensical mix of content knowledge and participation in these extracurricular activities.\n- Pillar 2 (Resistance to bias): Instructors tend to offer extra credit for activities that require an appreciable amount of time outside of class, expose students to new ideas, or offer a good challenge. Struggling students and students whose life circumstances preclude extra time to devote to schoolwork will tend to not take extra credit opportunities. It ends up being exactly the students who do not need extra credit who end up getting it.\n- Pillar 3 (Motivation): Students who tend to be unable to participate in extra credit opportunities can feel demotivated knowing about these missed opportunities. Further, whether related to course content or not, extra credit demotivates true learning by incentivizing the accumulation of points. If students view any earned points equally (whether they come from extra credit or the assessments of course content), then including extra credit derails learning of the primary material that instructors truly care about.\n\n### Use alternative (non-grade) consequences for late work and cheating\n\nIt is common to deduct points for late work and for academic integrity violations (on top of school-mandated punishments for integrity violations). These point loss policies embody a punishment system focused on **deterrence** of and **retribution** for bad behaviors. Feldman advocates instead for a **rehabilitation**-centered system: students have a chance to turn in late work without a grade penalty and to repeat the work on which they cheated, as opposed to losing points.\n\n- Pillar 1 (Mathematical accuracy): Deducting points for late work mixes the *timing* of student performance into a grade that should only reflect the *quality* of student performance. Deducting points for cheating results in a number that does not reflect a student's knowledge. By definition, work that is copied does not represent a student's understanding and deserves a missing or NA grade. This further underscores the merits of rehabilitative punishment—having students repeat the work on which they cheated is the only way to observe their true understanding and fill in the missing grade with an accurate one.\n- Pillar 2 (Resistance to bias): Grade consequences for late work tend to affect more vulnerable students. These students might have significant time commitments outside of school that make it difficult to hand in work on time. These difficult personal circumstances can also explain why students cheat: with a grading system that harshly punishes lateness, they feel that there is no other way to complete or succeed on the assignment.\n- Pillar 3 (Motivation): Grade consequences for late work and cheating can result in a vicious cycle: the demotivation resulting from the grade punishments results in further late work and cheating in desperate attempts to catch up.\n\n### Exclude \"participation\" and \"effort\" from the grade\n\n\"Participation\" and \"effort\" categories within the course grade broadly encompass desirable behaviors that the instructor wants to encourage (e.g., speaking in class discussions, contributing to group work, asking questions, attempting assignments). Including such categories results in inequitable grades.\n\n- Pillar 1 (Mathematical accuracy): Grades should reflect students' understanding of course content. \"Participation\" and \"effort\" indicate nothing about this understanding.\n- Pillar 2 (Resistance to bias): The components of \"participation\" and \"effort\" that instructors decide to include in the grade arise completely from their values. These values generally reflect a very narrow view of what it takes to be academically successful. Students who do not fit this narrow mold end up suffering despite their understanding of the course material. Further, there may be cultural reasons (school culture, classroom culture, etc.) underlying lack of participation from some students. Grade penalties for non-participation can perpetuate cycles of negative outcomes for certain groups.\n- Pillar 3 (Motivation): The same problems arising from Pillar 2 can result in demotivation and a loss of faith in the learning system.\n\n### Use only summative assessments in the grade, not formative assessments\n\nThis is effectively a \"No homework in the grade\" policy. This may seem controversial to instructors and perhaps terrifying to students (\"100% of the grade is exams!?\"), but coupled with a policy of offering retakes (described below), this can be a part of an equitable grading framework.\n\n- Pillar 1 (Mathematical accuracy): Formative assessments, like homework, are meant for students to **practice** their understanding. They should be a source of feedback but not a source of evaluation. To include formative assessment scores in the final grade would result in an inaccurate representation of students' ultimate understanding because these assessments are part of students' learning **journey**.\n- Pillar 2 (Resistance to bias): Grading homework for correctness can have disproportionately negative effects on the most vulnerable students who may lack the time to complete homework due to weaker understanding and/or external commitments. For fear of losing points, they may not attempt the homework or resort to copying. Both acts prevent them from practicing the material, which was the main goal of homework in the first place.\n\n### Renaming grades\n\nInstead of using a 0-4 or A-F scale, instructors can use short descriptors. Example: Exceeding Standards, Meeting Standards, Approaching Standards, Not Yet Met Standards, Insufficient Evidence.\n\n- Pillar 3 (Motivation): Renaming grades in this way can clarify expectations for each grade level, dispel the tendency for students to over-judge themselves based on grades, and prompt students to think about grades guiding their learning as part of a growth mindset.\n\n### Retakes and redos\n\nTo truly allow students to learn from their mistakes, instructors should give students the opportunity to retake portions of summative assessments that indicate room for improvement.\n\n- Pillar 3 (Motivation): Having the opportunity to try again can alleviate some students' testing anxiety and show them that their instructors truly care about their growth. This can motivate students to aim higher than they would have normally.\n\n## Blending the two frameworks in course preparation\n\nIn this section, I'll discuss policies that I've adopted and questions that I ask myself when preparing a course that uses a specs-equity grading system.\n\n### Iterate between writing learning objectives and assessments\n\nI have never been organized enough to write all of my assessments before the start of the course, but in implementing a specs-equity grading system, I think it would be useful to draft assessments in parallel with writing learning objectives for a few reasons:\n\n- This can help me identify \"implicit\" skills that I have not expressed as an explicit learning objective. A common example in my courses is the ability to recognize which of many concepts or tools is most useful for a given problem. By writing learning objectives and assessments in tandem, I could more easily recognize that \"Identify relevant tools\" should be its own learning objective.\n- Drafting assessments early also prompts me to draft rubrics early. Although this front-loads a lot of work, this should result in a more manageable workload during the semester.\n- Having early assessment drafts helps me shape my course schedule, which in turn guides my thinking on the type and timing of metacognitive activities for my students. This helps me decide if I want dedicated learning objectives for metacognition.\n\n### Bundling to determine the course grade\n\nIn a bundling approach, students must pass a particular set of assessments to earn a particular final course grade. If crafting assessments such that each assessment targets one learning objective, this amounts to each course grade being linked to mastery of a specific set of concepts. In my opinion, bundling (rather than assigning points to passed assessments) is the optimal way to use specs grading to determine course grades for a couple of reasons:\n\n- For one, the transparency of knowing exactly what concepts need to be understood to earn each letter grade is beneficial for both me and my students. I like being able to communicate to colleagues and potential future employers exactly what a student understood from my course. Students like having clear expectations.\n- Further, bundling can serve as a great signal to the most important ideas in the course. If the objectives that need to be mastered for a D are a subset of those required for a C (and so forth), students can clearly see that the objectives required for a D are crucial concepts.\n\n### Renaming pass/fail scores\n\nTo encourage a growth mindset, I prefer to rename pass/fail scores to Meets Standards (MS) and Not Yet Meeting Standards (NY).\n\n### What assessments to use?\n\n- Quizzes and exams\n    - In some courses, there are concepts that are so fundamental that they need to top of mind (e.g., knowing the appropriate types of data visualizations to make for the variables of interest). Are there enough of these concepts that warrant regular, timed, in-class exams?\n    - I prefer more frequent quizzes to a couple of large exams because frequent quizzes provide numerous retake opportunities, which can reduce testing anxiety. Later quizzes can include questions on earlier learning objectives that only need to be completed by students who have not yet mastered the concept. To manage time constraints, quiz questions on current content can be designed to only take, say, half of the class period. The hope is that the other half of the class period is sufficient for students pursuing retakes to finish the associated parts of the quiz.\n    - In *Grading for Equity*, Joe Feldman notes that retakes are only equitable if they are mandatory—the most vulnerable students might be reluctant to choose to pursue a retake opportunity for a variety of reasons. My takeaway from this is that instructors should strongly consider any potentially beneficial activity to be mandatory in order to promote equity.\n- Homework\n    - What is the role of homework? If using quizzes and/or exams, is the purpose of homework primarily to practice for these summative assessments? If so, I'm in favor of Joe Feldman's \"no formative assessments in the grade\" policy. Providing full solutions and offering formative feedback for the most crucial exercises should be enough to help students learn and practice, but excluding them from the grade can relieve students' time pressures and anxieties.\n    - Aside from traditional problem sets, I have also tried writing-intensive assignments which required students to explain statistical concepts in their own words. I was comfortable including this type of homework in the grade because they comprised a semester-long assignment that had flexible deadlines and constant opportunities for revision.\n- Projects\n    - If students begin projects towards the end of the course, grading them on a pass/fail scale can cause stress for students because of the shorter amount of time available for feedback. Clear specifications for good work are always necessary, but in this case a finer scale than a pass/fail scale might be necessary. This can still form a part of a bundling approach to determining the course grade: each letter grade is associated with a minimum project grade—in addition to a required set of learning objectives to have mastered by the end of the course.\n    - If the project spans the entire course and students are able to start early, a fully specs grading approach is completely feasible. Project milestones can be graded on a pass/fail scale with the opportunity to revise non-passing milestones throughout the course.\n\n### What is the role of group work in the course?\n\nActive learning in groups is a major part of class time in my courses. In place of a lecture, students watch videos and/or complete readings before class. During class, they work on exercises in groups to practice the ideas from the pre-class material. Overall, my students have appreciated this opportunity to practice and ask questions while I am present to help and classmates are there to collaborate. However, this style of learning can be challenging for some students who prefer different ways of learning or who don't develop a good rapport with group members. For these reasons, I have started to consider the framework of [complex instruction](https://complexinstruction.stanford.edu/).\n\nComplex instruction is a style of pedagogy that centers group work through the use of \"groupworthy\" tasks—tasks that truly require varied mindsets, opinions, and skills. While some students have found it helpful to be in groups to talk through the concepts prompted by my in-class exercises, there is nothing truly groupworthy about the exercises—nothing that truly necessitates diverse mindsets and skills. Although I have been guilty of using group projects rather than individual projects to cut down on my workload, I would like to be more intentional about group work in my courses going forward. Complex instruction captures exactly what I want in group work: the opportunity for students to engage in meaningful tasks together to promote better learning for everyone. Alana Unfried's talks at [ECOTS 2020](https://causeweb.org/cause/ecots/ecots20/breakouts/1) and at [USCOTS 2021](https://causeweb.org/cause/uscots/uscots21/keynote/3) are excellent resources for learning more about complex instruction.\n\n## Summary\n\nSpecifications grading brings to the table the specific practice of creating pass/fail criteria for student work. When used throughout a course, this framework can lead to heightened clarity for instructors and students. This benefits instructors with time savings during grading and improvements in communication about student understanding. This benefits students by making clear what they need to do to succeed, which can motivate them to aim higher. The pass/fail nature of specifications grading naturally pairs with the policy offering retakes on assessments, which is a core part of an equitable grading approach. Feldman's equity grading approach builds on this to encourage thinking more broadly about student motivation, the role of instructors' implicit biases and of student's life circumstances in grading practices, and the accuracy of grades in reflecting students' ultimate understanding. Considering the implementation of these practices in our courses can lead to better outcomes for both students and instructors.\n","lastmodified":"2022-12-08T21:09:07.526176752Z","tags":null},"/Graph-based-knowledge-representations":{"title":"Graph-based knowledge representations","content":"\nAcademics, we are at the precipice of a revolution in how we interact with content.\n\nSoon, books and articles will no longer be the dominant ways of interacting with concepts and ideas.\n\nA movement towards interconnected, graph-based interfaces to content is taking shape.\n\n## The limitations of linear forms\n\nWhen I refer to books and articles, I really just mean linear representations of content: a beginning and an end with content in between that is consumed in order. This is the default mode when we engage with books, blog posts, news articles, journal articles, and even videos.\n\nWhat is so bad about linearity?\n\n- I've [[The quest to find invisible giants-the myth of progress|written previously]] on the drawbacks of linearity as an academic learning a new area through journal articles. Essentially, journal articles paradoxically suffer from a simultaneous redundancy and dearth of background information. Redundancy arises because introduction sections across articles in a given area are needlessly similar. Dearth arises when articles on complex topics don't provide easy access to background that would make the subject more accessible.\n- For the same reasons, linearity is also a problem for students. Standard course materials (readings, videos) are self-contained linear representations of information. However, students come into a course/learning experience with huge variation in background knowledge and preparation and inevitably need more than what these resources can offer. Students with poorer preparation need easy access to more background on prerequisite material, and students with good understanding need easy access to additional concepts to continue being challenged.\n\n\n## The promise of graphs\n\nGraph-based tools for navigating information have long been popular (e.g., Wikipedia), but only recently have creators been able to create such information systems themselves using graph-based note-taking tools like [Roam](https://roamresearch.com/) and [Obsidian](https://obsidian.md/). The simple but pivotal feature to [bidirectionally link](https://maggieappleton.com/bidirectionals) notes unlocks enormous potential for navigating between ideas.\n\nGraphs-based writing tools make it possible for creators and knowledge workers to build representations of knowledge that are:\n\n- **Compact:** Does the same idea resurface in multiple areas? No need to reinvent the wheel each time---just link to the note for that idea in the note for each area. This saves time for both creators and consumers.\n- **Flexibly navigated:** Inherent in a graph structure is the ability to immediately see and jump to related ideas. This is way too hard with books and scholarly journal articles.\n- **Easier to verify/check:** A refactored knowledge representation is like a system of unit tests in software engineering. Each note should ideally represent an atomic concept/idea: one that can't be broken down any further. These should be easier to check than long pieces of writing. The network structure also makes explicit the dependence between notes. Checking the assumptions behind an idea amounts to visiting the ancestors of a note, and checking the consequences of an idea amounts to visiting its descendants.\n- **Useful for understanding the trajectory of learning:** The sequence of notes visited offers valuable insight into a learner's background and interests. Recommender systems have huge potential here.\n\nKnowledge workers and creatives have already embraced the idea of [digital gardening](https://maggieappleton.com/garden-history). I'm excited to see the authors at [Scaling Synthesis](https://scalingsynthesis.com/) advocate similarly for [graph-based systems](https://scalingsynthesis.com/Q-What-is-a-decentralized-discourse-graph/) for synthesizing ideas in academia.\n\n## The vision\n\nLet's build information systems that will safeguard human knowledge rather than rely on existing systems that exclude and muddle.\n\n- Publishing research in a knowledge graph rather than (only) journal articles\n\t- I think this has the potential to remove the toxic competition of academia, address the replication crisis, hasten the production of high-quality knowledge, foster collaboration, and increase the surface area for serendipitous insights.\n- Design opportunities for interfacing with graph-based systems (phrased in terms of user questions)\n\t- Which notes have I visited? How are they connected to what I've been reading recently?\n\t- How can I store personal metadata (notes, reactions) on both notes and edges (links) between notes?\n\t- What is the quickest way to get up to speed on concept X?\n\t- What note should I read next?","lastmodified":"2022-12-08T21:09:07.526176752Z","tags":null},"/Lightning-Lure":{"title":"Lightning Lure","content":"\nWhenever my husband and I have a conversation with someone new, my heart races. Is he going to ask it or will I? It's usually him…but how will he ask it? He better time it well and not ask it right off the bat. Otherwise there will be stern words over dinner.\n\nThe conversation warms up with talk about hometowns, living in Minnesota, being new parents, the challenges of being first-time homeowners, jobs. Then a half second pause in the conversation, and I casually look at my husband. Is now the time?\n\n\"What sorts of hobbies are you into?\"\n\nMy breath catches. Quietly. I turn to our new acquaintances and listen with the eagerness of a 5 year old who has just broached the subject of ice cream to her parents, but I keep the outward composure of an adult. Suddenly my Fitbit buzzes, reminding me that I haven't taken 250 steps yet this hour. Crap. I want to walk in place but don't want to look absurd. I can feel my heart beating more quickly. I make a mental note to look at my pulse trace later to see how my heart rate changed during this exchange. But I stay focused on the conversation with utmost tranquility. \n\nHiking (\"We like day hiking but haven't been in a while.\"), gardening (\"Our backyard is a mess. It'll be our big summer project.\"), watching shows (\"Us too! Which ones do you like?\"). Oh, also we play Dungeons and Dragons.\n\nI grin like the Cheshire cat.\n\nTo invoke the spirit of the game, Dungeons and Dragons (D\u0026D) is my lightning lure. In the game, [Lightning Lure](https://blackcitadelrpg.com/spells/lightning-lure-5e/) is a spell that creates a brief electrical whip that pulls an unsuspecting figure towards the caster. In life, a lightning lure is an electrifying idea that sparks deeper connection and magnetism between souls.\n\nD\u0026D is many different things to different people: it's a group storytelling experience, a tactical war game, an outlet for artistic creativity, a way to get together with friends. I love the game for all of those reasons, but it entrances me at a much deeper level. I see it as a portal to alternate worlds, a realm where I can think about my [[12 Favorite Problems|biggest questions in life]].\n\nThe stories that we can explore through the game's campaigns are limitless. They allow us to explore ideas as expansive as the rise and fall of civilizations and as intimate as the relationship between a mother and a daughter. Fiction similarly has this universe of possibilities, but unlike fiction, D\u0026D offers players a chance to be protagonists in these stories. Whenever I think about a problem that I wish I could solve, I think about how I could explore it through a D\u0026D campaign.\n\nDungeons and Dragons energizes my thinking in all of the areas I hold dear. In a world where we can be set adrift in a storm of ideas, it is my lightning lure: the flash of light that transfixes and illuminates a path forward in the crashing waves.\n\n---\n\n*I am so grateful to [Chris Cordry](chriscordry.com), [Leo Ariel](leoariel.com), [Jack Warshaw](jackwarshaw.substack.com), and [Lavinia Iosub](lavinia-iosub.com) for their wonderful feedback on this piece that made ideas more clear and writing more fun.*\n","lastmodified":"2022-12-08T21:09:07.526176752Z","tags":null},"/Motivating-the-question":{"title":"Motivating the question","content":"\nApathy is the cancer of today’s classroom. Once it plants its nasty little head in a student’s mind, it can be one tough beast to eradicate. Complaints like “I don’t care about this” and “When would I even use this?” are frighteningly common in higher education and indicate a malady far worse than boredom: time wasted. Not only are students wasting time being in class, cranking out hours of work to learn material that won’t be retained or appreciated, but teachers are also wasting their time preparing mechanical, need-agnostic material that will ultimately make no impact on their students’ interaction with the world.\n\nIn one way or another, the point of education is to learn how to live in this world—whether to learn specific skills for a job that will pay for our livelihoods or to learn ideas that shape how we react to the people, laws, and situations around us. And one of the most important ways in which education applies in real life is in being able to recognize when and how different concepts pertain to the situation at hand. Too often in classrooms are we given the punch line before the build-up. As education blogger Dan Meyer [puts it](http://blog.mrmeyer.com/2014/developing-the-question-needs-improvement/), teachers are too excited to present the concept without spending an adequate enough time _motivating_ the question behind the concept. And the result is a lack of internalization of ideas, a failure to understand why the material being taught is relevant.\n\nAs I explained in my [last post](Perspectives%20on%20the%20Interactive%20Mathematics%20Program.md), the Interactive Mathematics Program (IMP) puts in an admirable effort to motivate the need for mathematical concepts. It presents a tough multi-faceted problem at the beginning of each unit and develops the need for various math topics as it pertains to this overarching problem. I felt that one of the most memorable and instructive units was one in which we attempted to solve the unit problem on the very first day without any formal tools whatsoever. The best part (though frustrating at the time for me) was that this was _really hard_. There is definitely something that can be said for having students try to do things inefficiently to learn the _merits_ of the concepts that teachers are so excited to get to. Or in Dan’s words, there is definitely something that can be said for \"being less helpful\"—not jumping straight to teaching students about power tools but momentarily convincing them that the logs on their desks can only be cut with butter knives.\n\nIntroductory statistics courses can definitely benefit from a more problem-oriented and \"less helpful\" mentality. For one, I think there is a deluge of formulae for students to learn, and most of the time, the reasons for using them were never really developed or lost in the memorization process. The topic of confidence intervals serves as a great example here. We drill into students’ minds that the formula for a confidence interval is an estimate plus or minus some multiple of the standard error. And we can tell them that the interval gives us a range of possible values for the true population mean. But why are these possible values good ones? Why do we even have to give a confidence interval? Why isn’t it enough to just say that the mean is _around_ 5, say? When do I ever see confidence intervals in real life?\n\nA better way to teach this idea than to present a formula and give a two-minute interpretation is to make students see how the idea of a confidence interval is one they are exposed to frequently but in disguise. One way to do this is to present the students with common types of advertisement tricks.\n\n\n\u003cimg src=\"http://images.teamsugar.com/files/upl2/1/15259/20_2009/ce49a981caec0edd_cheerios.preview.jpg\" width=550\u003e\n\u003cp class=\"caption\"\u003e\u003ca href=\"http://www.popsugar.com/food/FDA-Packaged-Foods-Health-Claims-Make-Them-Drugs-3147756\"\u003eImage credit\u003c/a\u003e\u003c/p\u003e\n\n\n\u003cimg src=\"http://lesliemyint.files.wordpress.com/2014/10/c7ae7-colgate.jpg\" width=550\u003e\n\u003cp class=\"caption\"\u003e\u003ca href=\"http://www.bitedowndeals.com/blog/category/preventive-dentistry\"\u003eImage credit\u003c/a\u003e\u003c/p\u003e\n\nThe statistics presented on these ads are instinctively somewhat convincing. Hey a 4% reduction in cholesterol is pretty good. Wow, 90% of doctors recommend this product! These are definitely worth buying! But we can also think about what numbers on these ads would make us less convinced of the products' worth. A cholesterol reduction of 0 to 1% would definitely not make me want to buy Cheerios. And I would be much less impressed by this Colgate toothpaste if 50% or less of doctors recommended it.\n\nNow we give the students data—several sets of data that support or fail to substantiate the Cheerios claim to varying degrees—and ask them to make their own conclusions based on this data. I would expect many of them to take the average lowering of cholesterol as a summary measure; some might look at the median or mode; some might look at the percentage of people who had their cholesterol lowered by some minimal percentage level. No matter how they choose to look at the data the key idea is that the students see how their chosen summary measure(s) vary from dataset to dataset. Sometimes the claims in the ad are supported, and other times they are definitely not. It’s just that companies often only report their summary measures and not how much that measure would vary had they tested their product on different groups of individuals.\n\nAfter this point, I think that students would be a little more ready to learn about confidence intervals because they have seen how advertisements, something they encounter all the time, can use (or really conceal) them in misleading ways. And no one likes being duped.\n\nThis is by far not the best way of motivating confidence intervals, but it is a lot more than can be said for the majority of introductory statistics classes. Just taking a little bit more time to think about the everyday applications of statistics can go a long way in making lessons less formulaic and more engaging, and this is something that the statistics community should strive for.\n","lastmodified":"2022-12-08T21:09:07.526176752Z","tags":null},"/Perspectives-on-the-Interactive-Mathematics-Program":{"title":"Perspectives on the Interactive Mathematics Program","content":"\nMy pre-college mathematics education was probably different from most others. Instead of adopting the standard approach of teaching Algebra I and II, Geometry, and Trigonometry, my school district took up the Interactive Mathematics Program (IMP), a problem-centric approach to learning the essential material from these subjects. The program was split into 4 courses, each the equivalent of a middle school year or high school semester, and each course was split into approximately 5 units. Each unit introduced a mathematically-oriented story, which gave rise to a guiding question that we sought to be able to answer over the course of the unit. For example, in the second year unit “Cookies”, we are introduced to the Woo’s, a family of bakers who wish to optimize their cookie baking choices to maximize their profits. The challenge though is that they have several constraints on their available ingredients and sales capabilities. Over the course of the unit, we learned several ideas related to systems of equations and inequalities that helped us answer this question.\n\nAlthough I didn’t appreciate it at the time, IMP was attempting to do something that is rarely seen in education these days but is extremely important: motivating the concepts. At the beginning of the “Cookies” unit, I remember that class immediately started off with an attempt to solve the unit problem—no instruction on the best mathematical techniques, just a lot of pain, backtracking, and guesswork. I remember being overwhelmed just after organizing the information provided on the family’s ingredient and sales constraints. And guessing potential solutions was memorably laborious: does it work to make 100 chocolate chip and 170 oatmeal raisin? Rats! That violates constraint 4! What about 150 oatmeal raisin? Nice! That’s allowed! Aw shoot, that makes less money than my 150 chocolate chip, 130 oatmeal raisin combo! Fifty minutes of this and I was pulling my hair out. There must be an easier way to do this! And there was! Which we came to learn over the course of the next month or so that we spent on the unit. This particular unit sticks out in my memory primarily because it did such a good job at motivating the need for the main mathematical tools that we were learning during the unit. Had I taken a standard algebra course, I know I would not have truly internalized the utility of what we learned during that unit. For the most part, IMP did a decent job at contextualizing math concepts, and I think that this is a quality that is lacking in higher education in general. In designing curricula, we are not doing enough to motivate the content of the course, and I plan to explore this idea much further in a future post relating to introductory statistics curricula.\n\nAnother aspect of IMP that is particularly well suited to higher education is its emphasis on summarizing and organizing knowledge gained over the course of a unit. At the end of every unit, students are required to create a portfolio of reflections, class notes, and assignments that were instrumental in their comprehension of the main topics. So for example, in my “Cookies” portfolio, I included the first day of class activity that had us take a stab at the unit problem. I also included my class notes on feasible regions and solving systems of linear inequalities. I also wrote a cover letter summarizing the goals of the unit, what I learned from the assignments that I included in the portfolio, and my impressions of how these concepts were useful in everyday life. Portfolio time was always a laborious and dreadful experience for me during middle and high school, but I recognize now how useful a practice it is for being serious about retaining knowledge. As a graduate student, I have been exposed to several fundamental concepts time and time again in different courses, and I have found myself consciously wishing that I had put together portfolios for many of the classes that I took during college. Not only is the act of putting together a portfolio an invaluable synthesis activity, but the portfolio also serves as a one-of-a-kind reference manual. Because it is a collection of notes, homeworks, etc. created, curated, and edited by you, it can be infinitely more readable then a textbook. If you want it to, it can contain all of the steps in the proofs of key theorems, all of the exhaustive explanation that you worked through on your own, all of the fine details that finally made a concept click. A portfolio is a mini-textbook written in the language of your mind and can thus potentially serve as a reference for a very long time. It is a wonderful idea for IMP to introduce this concept to younger students, and I feel that it would be very useful for many high school and college classes to adopt.\n\nSo essentially the Interactive Mathematics Program, though by no means flawless, takes steps beyond traditional education practices that definitely have merit. Its case-based structuring of learning and its emphasis on creating concept portfolios can really impact the depth of learning and are ideas that nearly all higher education courses can benefit from.\n","lastmodified":"2022-12-08T21:09:07.526176752Z","tags":null},"/Teaching-and-learning":{"title":"Teaching and learning","content":"\n- [[Perspectives on the Interactive Mathematics Program]]\n- [[Motivating the question]]\n- [[Adapting education style to improve relevance and practical skills]]\n- [[Teaching real math with computers]]\n- [[Fight every battle everywhere-this is science|Fight every battle everywhere: this is science]]\n- [[Grading doesnt have to suck|Grading doesn't have to suck]]\n- [[Coach, dont just teach|Coach, don't just teach]]\n- [[A different kind of learning objective]]\n- [[12 Favorite Problems-The key to classroom community|12 Favorite Problems: The key to classroom community]]\n","lastmodified":"2022-12-08T21:09:07.526176752Z","tags":null},"/Teaching-real-math-with-computers":{"title":"Teaching real math with computers","content":"\nAs per a friend’s suggestion, I watched Conrad Wolfram’s [TED talk](http://www.ted.com/talks/conrad_wolfram_teaching_kids_real_math_with_computers) on reforming mathematics education. He advocates increased use of computers in the classroom and, in particular, champions the idea of teaching math via programming. There were a lot of ideas both in and missing from his talk that I found interesting to think about.\n\n## Mathematics can be taught via programming\n\nMr. Wolfram points to the procedural and algorithmic nature of mathematics to say that a fuller understanding of mathematics can be achieved by having students write programs that implement concepts. I completely agree that if you truly understand a concept, you can program it, but it’s worthwhile trying to consider how this might actually play out in middle and high school curricula.\n\nIt is useful to think about why this was such an interesting idea to many people in the first place. (It did get a TED talk after all.) The main point is that programming is not something that most people have any real idea of until they try it. I really didn’t understand what programming was about until I took an introductory class in college. I ended up loving it because I enjoyed the thorough and organized type of thinking that it encouraged, and I saw how useful it could be. People who are programmers or use programming regularly, like Mr. Wolfram, are very much convinced of its utility and are naturally excited about introducing this type of thinking earlier on in the education process. There are a few points that came to mind when weighing the pros and cons of a programming-oriented mathematics education:\n\t\n### Programming can be a great way to reinforce concepts\n\nI remember learning how to solve the tower of Hanoi puzzle in the children’s section of museums and in puzzle games long before I saw it again in my freshman year programming class. If placed before me, I probably would have been able to go through the motions from rough recollections or intuition, but the task at hand was to write a program that would solve an arbitrary tower of Hanoi puzzle (i.e. with any number of discs). Suddenly rough intuition needed to be transformed into a precise set of instructions, and it was the fact that I was seeing a familiar problem recast in a more general way that made the exercise relevant and memorable.\n\nWith standard pre-college mathematics education, a similar strategy could be adopted. As a specific example, solving systems of two equations with two unknowns is a standard algebra topic that could benefit from programming-type exercises. After students learn the technique of solving these problems, they hone their skills on practice problems and ideally are able to develop intuition on how to solve them by sight. Making this intuition more precise is where a programming exercise could come in. After students gain facility with solving the problems, we have them make their understanding more rigorous by asking them to write a very specific set of instructions to solve any such system of equations. Suddenly they must think about how _exactly_ they choose the scaling numbers for the equations and how they choose to add or subtract the two equations.\n\n\t\n### Programming is probably not the best way to introduce a topic\n\nJust because an activity truly assesses understanding doesn’t mean that it automatically lays the foundation for a lesson plan. If all of my algebra lessons had been formatted as a series of instructions in the way that a programming perspective would emphasize, I know I would have enjoyed my math class a lot less. And I definitely would not have been ready to write a program to solve arbitrary systems of equations the day the topic was introduced. When material is presented as formulaic, as a procedure, students are compelled to simply memorize the steps involved in solving problems. The intuition is removed, and the concepts don’t stick past the next test. I still think that teachers should strive to motivate the material as much as possible—whether that be through telling a story or getting students to see how useful the concept can be. This is important in both a classroom instructional setting and in a homework design setting.\n\n### Some features of programming can be useful for structuring material\n\nOne of the main reasons why people write code is to organize groups of related procedures and perform them in a consistent way in many different occasions. I can see this being useful in a geometry classroom, for example. Students could organize their knowledge of geometrical formulas by having classes containing functions used for computing perimeters, areas, and volumes. Also, the process of writing the actual functions is an exercise in helping students remember precisely what quantities are needed to calculate others. The way that students would end up using these functions is another source of excitement for people who code regularly. Students would use their library of geometry functions to solve more involved problems by creating an organized sequence of function calls to solve each step of the problem in sequence. Programmers love being able to clearly see the overall flow of a complex procedure as a sequence of smaller tasks. Essentially, the function-oriented nature of programming enables students to put [knowledge units](http://simplystatistics.org/2015/02/04/knowledge-units-the-atoms-of-statistical-education/) into a documented story-like framework, which hopefully would encourage big picture understanding.\n\n\n## Technology can enrich education, not \"dumb it down\"\n\nWhile Mr. Wolfram’s big idea was to use programming to teach math, I think the main subtheme of his talk was the increased incorporation of technology in math classrooms. Not \"[technology for technology’s sake](http://www.informationweek.com/mobile/ipads-in-the-classroom-worth-doing-right/d/d-id/1110490?)\" in terms of gadgets like [Smartboards](http://theinnovativeeducator.blogspot.com/2010/05/why-smartboards-are-dumb-initiative.html) and iPads, but thoughtfully constructed, computer-oriented lesson-plans, assignments, and activities. Technology, when appropriately used, can enrich education, and I think that the main avenue for this is through simulation and exploration.\n\nSimulation can be an amazing activity for getting students to think about real-world applications of what they are learning. For example, a lot of the simulations provided on [this site](http://serc.carleton.edu/sp/library/simulations/examples.html) have to do with the very practical task of learning about economics and could quite feasibly fit into an algebra curriculum. Just covered equations of lines? Well how about reinforcing those concepts and showing their utility by exploring linear trends that pop up in economics? If it is not common already, simulations should be more seriously considered by educators as add-on exercises to enhance a curriculum. I find simulations appealing as a teaching tool because they allow students to quickly try lots of things, allowing them to see a wide variety of phenomena in a short span of time. Most importantly, this allows them to **discuss** and **write** much more just because they have observed so much that they can comment on. Talking, and even more so writing due to its slower and more structured nature, is a [great way](http://files.eric.ed.gov/fulltext/ED544239.pdf) to assess the extent to which students understand a topic, and if high quality writing is emphasized, it can really get students to internalize ideas. So in short, technology should be used as a means of facilitating a high volume of **exploration** so as to facilitate more **writing** and **discussion**.\n\n## Summary\n\nProgramming can definitely enrich math education by helping students organize concepts and reinforce their understanding of the material. However, we still have to make sure that we motivate material and put it into a memorable context for students. Regarding the broader goal of increasing the presence of technology in education, expensive and ineffective approaches should be abandoned for activities that can be performed on computers and equipment already available in schools. Activities such as simulations can markedly deepen investigation of a topic and are easily performed with the materials available in most classrooms. Amending curricula to incorporate these ideas and activities might involve some time investment, but it could definitely improve the quality of student learning.\n","lastmodified":"2022-12-08T21:09:07.526176752Z","tags":null},"/The-Book-of-Why":{"title":"The Book of Why","content":"\nI just finished reading *The Book of Why* by Judea Pearl and Dana Mackenzie, and I really enjoyed it. I had been wanting to read it for some time now because I know very little about methodology relating to causal diagrams and structure learning. The book provides an overview of the main ideas that formed and historical events that led up to what Pearl calls the \"Causal Revolution\", a burgeoning of the direct interrogation of causation as opposed to its implicit renouncement in science for a period before then. Much of the causal inference methodology that Pearl discusses in the book is his own, namely that of causal diagrams and *do*-calculus. In light of his own methods, he also discusses techniques that are popular in disciplines such as psychology and economics. He also discusses another major framework for causal inference, the Rubin causal model. In reflecting on the book, I found it useful to organize my thoughts according to major themes I saw in the book.\n\n## Language and diagrams\n\nRight from the introduction, Pearl emphasizes the importance of language in science:\n\n\u003e My emphasis on language also comes from a deep conviction that language \n\u003e shapes our thoughts. You cannot answer a question that you cannot ask, \n\u003e and you cannot ask a question that you have no words for. (p. 10)\n\nI love this quote because it echoes how essential careful language is for humanity's progress. We cannot understand an idea without expressing it in some language in our own minds. We cannot transfer this understanding faithfully to others without carefully crafting language. This crafting of language affects how others understand, consume, act upon, and transfer the idea. And the cycle repeats. Essentially, language governs our intellectual progeny, which has profound scientific, moral, and cultural implications. There is even a growing body of scientific evidence regarding specific ways in which language shapes our thoughts. A [TED talk by Lera Boroditsky](https://www.ted.com/talks/lera_boroditsky_how_language_shapes_the_way_we_think) discusses some of these.\n\nWhy does Pearl emphasize the importance of language for causal inference? It has to do with precision, and it reminds me of a scene from Lois Lowry's *The Giver*.\n\n\u003e \"What is it, Jonas?\" his father asked. \n\u003e \n\u003e He made himself say the words, though he felt flushed with \n\u003e embarrassment. He had rehearsed them in his mind all the way \n\u003e home from the Annex. \n\u003e \n\u003e \"Do you love me?\" \n\u003e \n\u003e There was an awkward silence for a moment. Then Father gave a \n\u003e little chuckle. \"Jonas. You, of all people. Precision of\n\u003e language, please!\"\n\nEarlier in the book it is revealed that the reason for the strict adherence to precision of language in Jonas's community is to avoid unintentional lies that can come about through exaggeration or misinterpretation. We learn quickly in the story that this precision of language creates a dystopia, devoid of true feeling and the emotions that make up a beautiful human life.\n\nA bleak picture in the case of *The Giver*, but the existence of a language that allows for precise expression is indispensable when it comes to science! Consider the following epidemiological investigation: we want to know how the consumption of red meat influences risk for colon cancer. There are two questions that we might think of quickly.\n\n1. Does eating red meat cause an increase in colon cancer risk?\n2. How much red meat consumption is needed to increase the risk of colon cancer?\n\nMy impression is that the first question is how the majority of the public perceives a causal effect. *Does* exposure cause outcome? Pearl explains that this conventional way of thinking about causal analysis is really not the goal of the field at all:\n\n\u003e Many people still make Niles's mistake of thinking that the goal \n\u003e of causal analysis is to prove that X is a cause of Y or else to \n\u003e find the cause of Y from scratch. That is the problem of causal \n\u003e discovery. (p. 79)\n\n(Niles was a critic of path analysis/causal diagrams.) The goal of causal analysis is to quantitatively estimate causal effects while fully capturing the state of the analyst's current knowledge. The full capturing of current knowledge is achieved by drawing a causal diagram.\n\nThe second question, though quantitative, is still imprecise. It gets more at the estimation goal of causal analysis, but its imprecision leads to individual interpretations of the best way to proceed (essentially researcher degrees of freedom). Certainly there will be differences between individuals in terms of what they feel is the current state of knowledge on a subject. That is, experts may disagree on their causal diagrams. This disagreement is ok as long as their working set of assumptions (the causal diagrams) are made explicit. Usually when researchers ask a causal question like number 2, researcher degrees of freedom abound in both the variables considered and the manner in which the variables are handled in the analytic method.\n\nBoth of these issues can be avoided by using causal diagrams and the accompanying language of *do*-calculus. Causal diagrams are a means of precisely representing current knowledge. *Do*-calculus consists of a set of rules that allow us to express a causal quantity that we want to estimate in terms of quantities that can be computed from data. That is, it is a set of rules that allows us to express the effect of an **intervention** in terms of observational data quantities. An interventional effect is specified with the *do*-operator as with $P(Y \\mid do(X))$ to indicate a deliberate intervention. This is usually quite different from the observational quantity $P(Y \\mid X)$ as a classic confounding example illustrates. Let $Y$ denote reading ability and $X$ denote shoe size. We all know that age confounds the relationship as it is a cause of both shoe size and reading ability (provided the individual benefits from education). Were it not completely insane, intervening on shoe size would not change $P(Y \\mid do(X))$, but the observational quantity $P(Y \\mid X)$ does change as $X$ changes.\n\nIt was not intuitive for me that the effect of an intervention that has not actually been carried out could be estimated from observational data, but Pearl builds up these ideas in *The Book of Why* to explain (in Chapter 7) that 3 rules of *do*-calculus suffice for determining if a particular causal effect can be estimated from observation data given a causal diagram. [This blog post](https://www.inference.vc/untitled/) gives more technical details about causal diagrams and *do*-calculus, and the [introductory paper](https://arxiv.org/abs/1305.5506) cited in that post explains the 3 rules in detail.\n\nThe combination of causal diagrams and *do*-calculus is a powerful idea for me because of the precision of language that it offers for making causal queries. We first must lay our assumptions bare with a causal diagram. This was not a hard point to sell me on because I am already a firm believer in the power of network methods to organize domain knowledge. *Do*-calculus on the other hand is quite surprising. Still, the 3 rules provide clear guidelines on how to express a causal effect from observational data, and this clarity in allowable expressions is for me a compelling motivator for their use. Pearl mentions in the book that these rules have been algorithmized, and in my brief searching, I have found the R package called [daggity](http://www.dagitty.net/) that seems to implement the rules of *do*-calculus.\n\n## History\n\nAnother major theme of this book is understanding history. One entire chapter is devoted to tracing the history of how causal inference came to be. Pearl and Mackenzie start by recounting the tale of Francis Galton, a British scientist who was on a quest to understand the genetic determinants of features like height and intelligence. He eventually stumbled upon the phenomenon of regression to the mean and saw it as a physical, casual process because it was able to reconcile some peculiar features of models that he had developed for height distributions across generations. However, he eventually grew dissatisfied with the idea after finding that the phenomenon persisted regardless of which variable was treated as the causal agent. He was never able to resolve his initial causal queries about genetic determinants, but he did pass on ideas of scatterplots and correlation to future generations of statisticians. In particular, Karl Pearson took to the idea of correlation quite excitedly and came to eschew ideas of causality, which he viewed as imprecise and vague in contrast to his clean, mathematized correlation coefficient. Such was a major force behind the lack of causality research in statistics for some time. Pearl and Mackenzie end this historical chapter with the tale of Sewall Wright, who seems to have been one of the first to come up with the idea of using causal diagrams. Through Wright's tale we see a reemergence of the willingness to study causality rigorously and quantitatively.\n\nThis historical discussion is fascinating because it allows us (with our hindsight goggles on) to understand why research progressed the way that it did. Through understanding the personalities and culture of these historical figures, we can understand why certain ideas were pursued, why shortcomings arose, and hopefully mediate ourselves to be better scientists because of this understanding.\n\n## Cognition\n\nThe importance of an awareness of human cognition is also a recurring idea in the book. Pearl motivates his journey through causal inference with his interests in artificial intelligence, and he claims that causal inference methods should ideally try to emulate the powerful causal reasoning faculties within our own minds that stem from simply asking the question: why? I like the apparent simplicity of this. It is easy to see how asking this question could give rise to causal diagrams. Each \"because\" becomes a directed connection from nodes that represent variables in our \"because\" statement. Still, at the same time, I wondered: should there not be some higher standard to which causal inference methods should aspire? Why simply aim to replicate human reasoning? Shouldn't we strive for our methods to achieve something *more* than just human reasoning in some sense? After thinking about this, I feel that these goals are too lofty. We humans are limited by our capabilities, so even if causal inference methods could achieve beyond-human reasoning, we wouldn't *know* that they were. Given a method that produces some results, we would still evaluate the method by asking, \"Do those results make sense?\" We would still be using our (powerful) causal reasoning capabilities to make sense of the results generated by the method. Thus even if some deeper meaning was somehow conveyed by the method, the meaning we would be able to extract from it is limited by the framework of our understanding. I feel that Pearl's claims about using human reasoning as a gold standard for causal inference methods is reasonable. This thinking also reaffirms my belief in the importance of understanding how humans interact with the tools we develop, such as through the fields of ergonomics, human-computer interaction, human-data interaction.\n\nAn awareness of human cognition is explored most extensively in a chapter on several paradoxes: the Monty Hall problem, Berkson's paradox, Simpson's paradox, and Lord's paradox. I had actually never heard of Berkson's paradox, but it is the appearance of an association in a subpopulation that is not seen in the general population. Pearl explores all of these paradoxes in light of causal diagrams, and I actually did find it helpful to view these problems with this causal lens. The causal diagrams were useful in generalizing the structure of the situations governing the paradoxes, which I think is helpful in recognizing when they occur. Further, Pearl lays forth a reasonable set of criteria for dealing with paradoxes:\n\n\u003e Any claim to resolve a paradox (especially one that is decades old) \n\u003e should meet some basic criteria. First, as I said above in connection \n\u003e with the Monty Hall paradox, it should explain why people find the \n\u003e paradox surprising or unbelievable. Second, it should identify the \n\u003e class of scenarios in which the paradox can occur. Third, it should \n\u003e inform us of scenarios, if any, in which the paradox cannot occur. \n\u003e Finally, when the paradox does occur, and we have to make a choice \n\u003e between two plausible yet contradictory statements, it should tell us \n\u003e which statement is correct. (p. 202)\n\n## Teaching\n\nBy its nature, the book aims to inform readers about the development of and about central ideas in causal inference, but teaching and pedagogy are not direct themes of the book. That being said, I was amazed at how appropriate the writing of the book is for a classroom textbook. There are a lot of great thought experiments, historical examples, and activities to engage students at the undergraduate level and beyond. In particular, the chapters that recount the evolution of the smoking-lung cancer debate (Chapter 5) and that explore \"statistical\" paradoxes through a causal lens (Chapter 6) are great sources of classroom content.\n\n## Conclusions\n\nI highly recommend this book to anyone who cares about science. Even if causal inference isn't an area of interest for you, the ideas in this book are important for understanding the causal research that we otherwise consume or hear about. Pearl is very invested in these ideas, so the language in the book is very enthusiastically in favor of these methods. I can see how this might irritate some readers, but I found that the ideas he presented were compelling and interesting in their own right. Certainly these methods are not a panacea, but I do believe that they can be quite useful. Reading the book has motivated me to continue learning about these topics, and I hope that I can eventually fully understand the answers to some questions I was left with:\n\n- Is there no reconciliation at all for Rubin causal model type methods and *do*-calculus methods?\n- How can causal diagrams and *do*-calculus be used to study networks that evolve with time?\n- How is interference between units handled?\n- How can we measure the causal effect of several variables simultaneously?\n- I have heard of edges being random variables in the graphical model literature. (i.e., Arrows can point to arrows.) Is this part of the *do*-calculus framework?\n","lastmodified":"2022-12-08T21:09:07.526176752Z","tags":null},"/The-quest-to-find-invisible-giants-the-myth-of-progress":{"title":"The quest to find invisible giants: the myth of progress","content":"\nSir Isaac Newton once said, \"If I have seen further, it is by standing on the shoulders of giants.\" This quote has come to represent the admiration of progress in human knowledge. It's a beautiful quote. It inspires: it prompts us to look forward, to yearn to see further. It humbles: it turns our gaze backwards for a moment, to pay homage to the labors granting us these higher vantage points.\n\nIn the modern age, it is a lie.\n\nNo quote could be more antithetical to how I feel as a learner.\n\n## A feast of futility\n\nI am an academic statistician. It is part of my job to keep up to date with statistical methodology by reading journal articles. Nothing makes me feel more hopeless. Every time I read a journal article, I feel a pang of dread when I reach the bibliography. All of the unread references stare at me with the hollow eyes of tormented souls. Even if I could read many of them, I know that the same fate would await me at the end of those articles. In my professional life, reading feels Sisyphean. As someone who aspires to the lighthearted joy of a nymph, I hate being so bleak in this regard.\n\nMoments of triumph do exist.\n\nSometimes I am able to fully read through an article with ease. However, these occasions are rare. My journey is more generally marked by frequent spars with despair, skirmishes I face by reaffirming a decade of advice–understanding scholarship is hard at first, eventually things will be easier, understanding everything isn't necessary.\n\nBut I'm not even trying to understand everything. I am only trying to understand the broad strokes of a subfield of my discipline, and it is a Herculean effort. Climbing to the ankles of giants should not be a quest of such epic proportions.\n\n## The tyranny of tradition\n\nBooks and articles have formed our predominant modes of communicating information. They are unquestionably useful, but they cannot be the *only* information chariots carrying us into the future. Their linear, self-contained structure should facilitate a streamlined learning experience, but the reality is a bacchanalian bungle.\n\nFor one, journal articles addressing similar topics languish under a plague of [backstory bloat](https://twitter.com/wes_kao/status/1467161815159300106). For example, in reading the statistical literature on generalizability of scientific studies, I've lost count of the number of times that I've effectively read identical introduction sections. Eventually l started skimming. Although I saved time by skimming, I was often waylaid by impenetrable methodology sections (the new stuff!). It was as if the authors used all of their ambrosia in writing the introduction.\n\nUnfortunately, publishing incentives in academia only augment this copiousness of context. When career advancement depends on producing a large number of quality articles, academics are encouraged to communicate multiple smaller advances in separate publications. Even benign motivations of wanting to share advances more rapidly leads to surges in article quantity, leading to a swell of redundant background information.\n\nFurthermore, books and articles stifle lateral learning journeys. When following linear narratives, our minds often stray sideways. What was that concept? Let me look that up. Interesting connection! Let me explore a bit. Citations serve as a crude map for these lateral journeys, providing titles of intellectual landmarks. But simply knowing where to go is about as useful as a fork in a death match against the Nemean lion.\n\nLet's tilt the limelight away from the linear and give **graphs** a chance at glory.\n\n## A gamble with graphs\n\nGraphs are a powerful tool for navigating information because of their ability to show ideas and the connections between them. Wikipedia is a perfect example of a graph-based tool for navigating knowledge in a nonlinear way and facilitating lateral learning journeys: articles are densely connected through a web of links that can be opened instantaneously.\n\nThe problem with Wikipedia is that article topics are overly broad, making many articles monolithic. In this way, links between Wikipedia articles are no better than citations in books and journal articles: navigating between concepts is like climbing a mountain.\n\n\u003cimg src=\"/images/invisible-giants-myth-of-progress/mountain.jpg\" alt=\"Navigating Wikipedia links and journal/book citations is like climbing a mountain\" style=\"display: block; margin-left: auto; margin-right: auto; height: 400px; border: 6px solid black;\"\u003e\n\nWe need a Wikipedia-like system in which we decompose complex topics into smaller atomic concepts and create links between these digestible building blocks. In this system, navigating between concepts would be like climbing stairs.\n\n\u003cimg src=\"/images/invisible-giants-myth-of-progress/mountain_stairs.jpg\" alt=\"Navigating an atomic concept graph is like climbing stairs\" style=\"display: block; margin-left: auto; margin-right: auto; height: 400px; border: 6px solid black;\"\u003e\n\nAn atomic concept graph has the potential to *motivate* and *empower* any knowledge worker through incremental understanding.\n\nSuch a graph would also reduce backstory bloat. The introductory information in topic-sharing journal articles would no longer need to be repeated: new ideas would simply link to the appropriate constellation of atomic concepts.\n\nTo see further by standing on the shoulders of giants is to understand enough of what has been built to contribute meaningfully in one's own work. Like Nyx's cloak, our default system of books and journal articles enshroud intellectual contributions in darkness, pierced by a select few with a means to illuminate the shadow. Countless others want to lift the veil. It's time to build the knowledge systems that will let them climb past ankles to those lofty shoulders in the clouds.\n\n---\n\n*I am grateful to [Leo Ariel](leoariel.com) and [Tobi Emonts-Holley](Tobisblog.uk) for their wonderful feedback and encouragement on this piece.*\n","lastmodified":"2022-12-08T21:09:07.526176752Z","tags":null},"/The-twin-brushstrokes-of-my-marriage-and-career":{"title":"The twin brushstrokes of my marriage and career","content":"\nI remember the day that I fell in love with teaching. A few weeks into my first graduate school experience as a teaching assistant, I stood in front of a sunlit classroom brushing the chalk off my jeans and looked at my students. No clacks of fingers on keyboards, no eyes glued to screens–just small nods, smiles as understanding finally came. Statistics has a bad reputation for being dry and challenging (\"You teach statistics? I *hated* that class in school!\"), but on that day, I felt like I took a wet cloth to a dusty mural to reveal some beauty beneath.\n\nWhen did things change? When did I start to notice how much dirt was caked on that damp cloth? Maybe it was a growing realization about the challenges of truly reaching every student. There have always been students whom I've struggled to reach, but in the beginning, that was fine. I thought nothing of the fact that I spent my walks to the gym, the recovery between reps, the bus ride home, thinking about those students. I mined my memory for every pre-class conversation, every group discussion I overheard, for clues about examples that would delight them and conversation starters that would inspire them.\n\nThis allegro vivace in caring for students was the only tempo I knew, and I continued to sustain this pace throughout my first few years as a college professor. But since the pandemic, it has beome untenable. There seem to be so many more students whose spirits lie locked behind a wall of diamonds. My efforts, my colleagues' efforts to chip away at that wall, to motivate, to connect, to understand, all seem futile. On top of that, every desperate confession of hopelessness at yet another case of student cheating or apathy is another chord of despair.\n\nOn top of that, in order to earn tenure, my college also expects me to produce impactful scholarship, as measured by my peers (just 2 of them!) who will be heavily influenced by the number of journal articles I have published and the reputation of those journals. This viewpoint has been both subtly and overtly reinforced in \"mentoring and support\" opportunities throughout my time as a junior faculty member, and as such, tenure was always on my mind. Every walk, workout, and drive that I spent thinking about my students, I also spent feeling guilty for not immediately thinking about my research and how to twist my [spiral-shaped passions](https://lmyint.github.io/writing/invisible-giants-myth-of-progress/) into shoeboxes. So I spent those crucial moments of mental recovery continuing to think at miles a minute.\n\nEnough.\n\nI have come to realize that the brush that has painted the fresco of my career is the same that has painted the watercolor of my marriage. Both began with captivation and have endured agony and strife along the way. My husband and I took the most important step for our marriage to date and sought therapy. It feels like we've opened up a new canvas. It's time for me to do the same for my career.\n\nLove is a verb. But the way that we use it as a feeling, the ultimate emotional aspiration that lets us glide through life, belies its true nature as a process. A process that requires labor from all parties involved. My husband and I have re-committed to this, and already I have seen color spread into our lives again.\n\nHigher education, let's give this another try. I need to make joy rampant in my work, and what I create will likely be unconventional. Please keep an open mind, and let the colors run.\n\n---\n\n*I am grateful to Ashley Rothwell-Campagna, [Chris Cordry](chriscordry.com), [Sachin Bhatia](sachinb.substack.com), and [Chris Wong](chr.iswong.com) for their invaluable feedback and support on this piece.*\n","lastmodified":"2022-12-08T21:09:07.526176752Z","tags":null},"/about":{"title":"About","content":"\n# On my mind these days\n\n- Graph-based ways of representing and navigating knowledge\n- How being a Dungeon Master is like being a teacher\n- The role of coaching in everyday interactions\n- [Why facts don't change people's minds](https://jamesclear.com/why-facts-dont-change-minds) (being kind does)\n- Statistics and data science pedagogy\n- Alternative grading\n- The future of education\n- Motherhood\n\n\n# Professional journey\n\nI am an Assistant Professor of Statistics in the Department of Mathematics, Statistics, and Computer Science (MSCS) at Macalester College. I received my PhD in Biostatistics from the Johns Hopkins Bloomberg School of Public Health where I worked with Kasper Daniel Hansen on statistical methodology for high-throughput biology and with Jeff Leek and Leah Jager on understanding the role of human behavior in data analysis.\n\n  - Download my [CV](https://www.lesliemyint.org/cv.pdf)\n\n\u003cstyle\u003e\n.meta {display: none;}\n\u003c/style\u003e\n","lastmodified":"2022-12-08T21:09:07.526176752Z","tags":null},"/garden":{"title":"Digital Garden","content":"\n## Entry points\n\nIf you want to get an idea of what is constantly on my mind, take a look at my [[12 Favorite Problems]] to start.\n\n- 🌶 Books and articles (linear knowledge forms) are poor forms for *safeguarding* knowledge. On this front, I think a lot about [[Graph-based knowledge representations]].\n    - Note: I'm not saying that we shouldn't use books and articles to communicate information. We shouldn't **ONLY** use books and articles. Graph-based representations are the future.\n- As a college educator, I think a lot about [[Teaching and learning]] and ways that they can be inspirational, joyful, and effective for both students and teachers.\n- What makes [[A beautiful life]]?\n\nOther essays that I need to make an entry point for:\n\n- [[The Book of Why]]\n- [[Dungeons and Dragons Web Scraping with rvest and RSelenium]]\n","lastmodified":"2022-12-08T21:09:07.526176752Z","tags":null},"/talk":{"title":"Presentations","content":"\n- [[talks/2022_08_10_jsm|Causal inference throughout the statistics curriculum]]    \n    [ASA Joint Statistical Meetings 2022](https://ww2.amstat.org/meetings/jsm/2022/) • Washington, D.C. • August 10, 2022\n\n- [[talks/2022_04_01_stthomas|A metabolic view of symptoms in kidney disease]]    \n    Applied Probability and Statistics seminar • University of St. Thomas • April 1, 2022\n\n- [[talks/2021_08_05_bioc|A package for exploring biomedical concept graphs: An alternative to manual literature review]]    \n    [Bioconductor Conference 2021](https://bioc2021.bioconductor.org/) • August 5, 2021\n\n- [[talks/2020_10_30_minne_wiads|What did I just read? Organizing knowledge from the research literature using graph databases]]   \n    [Women in Analytics and Data Science](http://minneanalytics.org/minnewiads2020/) • Minne Analytics • October 30, 2020\n\n- [[talks/2019_10_22_carleton|Graphs Galore!. Representing Knowledge in the Sciences and Humanities]]   \n    Statistics seminar • Carleton College • October 22, 2019\n\n- [[talks/2019_03_22_creighton|Statistical. methods for querying the regulatory role of DNA]]    \n    Dept. of Mathematics Colloquium • Creighton University • March 22, 2019\n\n\u003cstyle\u003e\n.meta {display: none;}\n\u003c/style\u003e\n","lastmodified":"2022-12-08T21:09:07.526176752Z","tags":null},"/talks/2019_03_22_creighton":{"title":"Statistical methods for querying the regulatory role of DNA","content":"\n\u003cspan class=\"slides\"\u003e[Slides](https://docs.google.com/presentation/d/1JtTMhWT8qZh9TiciD4UAHwRMJ5jGXqhqVNkSEG2O7Wg/edit?usp=sharing)\u003c/span\u003e\n\nDept. of Mathematics Colloquium • Creighton University • March 22, 2019\n\n**Abstract:** DNA is often called the blueprint for life because it encodes the information needed for our cells to function. A major way that DNA carries information is by encoding information needed to make proteins, a process called gene expression. However, it has been found that only a small fraction of DNA (about 1.5%) actually contains information to make proteins. What then does the rest of DNA do? A prevailing hypothesis is that much of DNA is involved in regulating its own expression. The fact that so much of DNA might fill this role makes testing these hypotheses a major focus in molecular biology research. In this talk, I'll discuss a relatively new biological assay that has been developed to test these hypotheses and the statistical methodology that we have developed to analyze data from these assays.\n","lastmodified":"2022-12-08T21:09:07.526176752Z","tags":null},"/talks/2019_10_22_carleton":{"title":"Graphs Galore! Representing Knowledge in the Sciences and Humanities","content":"\n\u003cspan class=\"slides\"\u003e[Slides](https://docs.google.com/presentation/d/1gh2qpDZhjUDgV-Qo2QZrADnGxwaD2qU7k-zNSHAjvOE/edit?usp=sharing)\u003c/span\u003e\n\nStatistics seminar • Carleton College • October 22, 2019\n\n**Abstract:** Knowledge moves forward by a continual integration of existing ideas with new findings. The problem nowadays is that there is so much research being conducted that it is difficult to fully be informed about all existing scholarly work. Text (in the form of research publications) is the main mode of storing the rich, interconnected knowledge that we are generating, and it is well appreciated to be a computational nightmare to work with. My goal in this work is to capture the information woven through text in a computable form that holds promise for building more solid future knowledge: graphs. In this talk, I'll discuss my ongoing efforts to use graphs to organize biological information from texts and how these ideas might also be useful for structuring knowledge within the humanities.\n","lastmodified":"2022-12-08T21:09:07.526176752Z","tags":null},"/talks/2020_10_30_minne_wiads":{"title":"What did I just read?","content":"\n\u003cspan class=\"slides\"\u003e[Slides](https://docs.google.com/presentation/d/1ACWVKLDd8DmSqYFzVBwp-Jz-rMRYhcLR1OL7sEVYsM4/edit?usp=sharing)\u003c/span\u003e\n\n[Women in Analytics and Data Science](http://minneanalytics.org/minnewiads2020/) • Minne Analytics • October 30, 2020\n\n**Abstract:** Staying up to date on the relevant results and methodology in our fields is crucial for doing our best work but can be challenging if the literature is vast. There are myriad ways in which people try to organize this information, from note taking to simply remembering. However, as the literature grows, it is not clear that these approaches are sustainable for most people. In this talk, I'll discuss how knowledge graphs, as implemented by graph databases, provide another alternative. Graph databases have the advantage of encouraging careful thought about how pieces of information are connected and also provide a means of performing computations on that information. In this talk, I'll introduce key ideas about graph databases and a use case in organizing information from statistical research literature.\n","lastmodified":"2022-12-08T21:09:07.526176752Z","tags":null},"/talks/2021_08_05_bioc":{"title":"A package for exploring biomedical concept graphs: An alternative to manual literature review","content":"\n\u003cspan class=\"slides\"\u003e[Poster](https://f1000research.com/posters/10-656)\u003c/span\u003e\n\n[Bioconductor Conference 2021](https://bioc2021.bioconductor.org/) • August 5, 2021\n\n**Abstract:** Within the biomedical sciences, both contextual sensemaking of results and hypothesis generation require strong knowledge of how many different concepts and physical entities are connected. Traditionally, these endeavors have required investigators to manually mine the vast amounts of information contained in research papers. The sheer volume of accumulated knowledge poses problems for both the breadth and depth of literature review. One goal of biomedical text processing efforts is to facilitate this process through computation. The Semantic MEDLINE database, maintained by the National Library of Medicine, is a freely available resource that contains a rich store of biomedical relational information. In particular the database contains over 100 million subject-predicate-object relationships (called predications), that form a graph of relationships between biomedical concepts. The Bioconductor package rsemmed provides a set of tools for flexibly exploring mechanisms and conceptual connections within this graph. This package should be useful to anyone looking to computationally explore the literature behind biomedical ideas.\n","lastmodified":"2022-12-08T21:09:07.530176974Z","tags":null},"/talks/2022_04_01_stthomas":{"title":"A metabolic view of symptoms in kidney disease","content":"\n\u003cspan class=\"slides\"\u003e[Slides](https://docs.google.com/presentation/d/1uftijB7_SF3Nz5jZCHoh4cNcPWgNMjK8z9_5zE4fAPk/edit?usp=sharing)\u003c/span\u003e\n\nApplied Probability and Statistics seminar • University of St. Thomas • April 1, 2022\n\n**Abstract:** Patients with advanced chronic kidney disease commonly experience debilitating symptoms, but the toxins that cause these symptoms are unknown. Metabolomics, the large-scale study of small molecules in biological samples, holds promise for identifying these toxins. In this talk, I'll discuss the statistical approach that my collaborators and I used to investigate the metabolic underpinnings of these symptoms using data from the Modification of Diet in Renal Disease (MDRD) study. In particular, I'll highlight common analysis frameworks used in studies of high-throughput biological measurements and the multi-pronged sensitivity analysis that we conducted to evaluate the robustness of our results.\n","lastmodified":"2022-12-08T21:09:07.530176974Z","tags":null},"/talks/2022_08_10_jsm":{"title":"Causal inference throughout the statistics curriculum","content":"\n\u003cspan class=\"slides\"\u003e[Slides](https://docs.google.com/presentation/d/12CEAyIN7lBn2PL03VJxc3YZ8la9yEo2C0vfYzXKfl9c/edit?usp=sharing)\u003c/span\u003e\n\n[ASA Joint Statistical Meetings 2022](https://ww2.amstat.org/meetings/jsm/2022/) • Washington, D.C. • August 10, 2022\n\n**Abstract:** Causal questions abound in everyday life, but the rote mantra of \\\"Correlation does not imply causation\\\" that is routinely taught in statistics courses leaves students wanting. If this caution is invoked at every turn, students may understandably wonder whether statistics is able to answer questions that interest them. My teaching in the area of causal inference has been guided by an emphatic desire to unseat this mindset. In this talk, I will discuss the concepts that I cover in a standalone capstone level causal inference course as well as causal ideas that I carry over to introductory and intermediate level courses in the statistics curriculum. My goal is to promote discussion among statistics educators about what causal ideas are most essential for students to grasp to be thriving members of society.\n","lastmodified":"2022-12-08T21:09:07.530176974Z","tags":null},"/teaching":{"title":"Teaching","content":"\nI teach the following courses at Macalester. Some of my courses have course websites which you can navigate to below. For many of my classes I make lecture videos, which can be found on my [YouTube channel](https://www.youtube.com/channel/UCgW3LCQ623sUjprV8EbtVoA).\n\n- STAT 125: Epidemiology\n- STAT 155: Introduction to Statistical Modeling\n    - [Class notes](https://bcheggeseth.github.io/Stat155Notes/) in collaboration with [Brianna Heggeseth](https://bcheggeseth.github.io/) and [Kelsey Grinde](https://kegrinde.github.io)\n    - [{S20}](https://lmyint.github.io/155_spring_2020/)\n- STAT 253: Statistical Machine Learning\n    - [{S19}](https://lmyint.github.io/253_spring_2019/), [{S21}](https://lmyint.github.io/253_spring_2021/), {S23}\n- STAT 451: Causal Inference\n    - [{S20}](https://lmyint.github.io/causal_spring_2020/), [{F20}](https://lmyint.github.io/causal_fall_2020/), {S23}\n\n\u003cstyle\u003e\n.meta {display: none;}\n\u003c/style\u003e\n","lastmodified":"2022-12-08T21:09:07.530176974Z","tags":null}}